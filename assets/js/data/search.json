[ { "title": "My honours thesis — minimum bases for permutation groups", "url": "/posts/honours-thesis/", "categories": "Epic Maths Time, Cool Stuff", "tags": "algebra, uni-maths", "date": "2022-12-14 23:50:00 +1100", "snippet": "I’m really excited to share my completed honours thesis! I’m honoured that my supervisors (and apparently the examiners too haha) were pleased with the result, and I’m humbled that my effort this year has led to graduating with first class honours — I owe it all to those who were there for me: my family, friends (especially my honours friends, church friends, Chris, and Wes), and God, whose love and presence sustained me through the busy times.My research was in minimum bases for permutation groups. A permutation group is, loosely speaking, a collection of permutations of a set (essentially rearrangements of the set) which, when applied in succession, remains in the collection; the reverse permutation must also be in the collection, as well as the identity (do nothing) permutation. A base is a collection of points in the set being permuted, such that if a permutation in the collection fixes every point in the base, then that permutation must be the identity.My goal was to talk about what is known about the smallest possible size of a base of a given permutation group, with use of the GAP computational language, and with original instructive examples interwoven throughout. I hope you find it interesting (or at least a pleasant read, which was definitely a focus and pride of mine) — and if you’re into group theory or maths in general, then I hope it may inspire you in your own work in some way. (You may want to watch the video below first, as it may clarify some basic content here in the thesis.)Below is a recording of my final honours presentation. I motivated my research using the Rubik’s group (permutations of the Rubik’s cube), which is one of the many applications of permutation groups, and one that is close to my heart (thanks Wes). I tried to make it fun and engaging with the Rubik’s cube example, and a bit more understandable for a wider audience — I hope you will find it as interesting as I did!While I might not be doing as much maths in the future, I hope to continue to review and share some more interesting things I’ve learnt along my mathematical journey. Despite going into full-time work not directly related to my field of study, my honours year was by no means a waste of time, and I am eternally grateful for this opportunity to spend 2022 studying something I’m passionate about. The following verse helped me get through these bittersweet feelings at the end of my honours year:“There is a time for everything,        and a season for every activity under the heavens”                — Ecclesiastes 3:1 (NIV)Thanks for coming along this journey with me, and I look forward to continuing in my new role at the Department of Education and Training and working towards better outcomes for education across our state!" }, { "title": "A generatingfunctionological proof of the binomial theorem", "url": "/posts/generatingfunctionological-proof-binomial-theorem/", "categories": "Epic Maths Time, New Perspectives", "tags": "combinatorics, algebra, uni-maths", "date": "2022-04-16 13:00:00 +1000", "snippet": "Make sure you have read the last post on generating functions first, else proceed at your own risk!Recall that for \\(k,n \\in \\mathbb{N}\\), the binomial coefficient is defined by\\[\\binom{k}{n} = \\frac{k!}{n!(k - n)!} = \\frac{\\overbrace{k(k - 1)(k - 2)\\dotsb(k - n + 1)}^{n\\ \\text{terms}}}{n!}.\\]You may remember from high school that for some \\(k \\in \\mathbb{N}\\),\\[(x + y)^k = \\sum_{n = 0}^k \\binom{k}{n} x^n y^{k - n} \\implies (1 + x)^k = \\sum_{n = 0}^k \\binom{k}{n} x^n = \\underbrace{\\binom{k}{0}}_{= 1} + \\underbrace{\\binom{k}{1}}_{= k} x + \\underbrace{\\binom{k}{2}}_{= \\frac{k(k - 1)}{2}} x^2 + \\dotsb + \\underbrace{\\binom{k}{k}}_{= 1}x^k.\\]This is the binomial theorem.The generalised binomial theorem: redefining binomial coefficientsBut what if we do not restrict $k$ to be a natural number above? This leads us to Newton’s generalised binomial theorem, involving the binomial series:Theorem 1 (binomial theorem). If \\(\\alpha \\in \\mathbb{R}\\), then\\[(1 + x)^\\alpha = \\sum_{n \\geq 0} \\binom{\\alpha}{n} x^n \\overset{\\text{ops}}{\\leftrightarrow} \\left(\\binom{\\alpha}{n}\\right)_n;\\]this is an equality in the formal sense, where we don’t care about convergence. (Note that the series converges when \\(\\lvert x\\rvert &amp;lt; 1\\) in the analytic sense.)What exactly does \\(\\binom{\\alpha}{n}\\) mean for \\(\\alpha \\not\\in \\mathbb{N}\\)? The factorials are no longer well-defined (even if we consider the Gamma function \\(\\Gamma\\) where \\(\\Gamma(n) = (n - 1)!\\) and enforce that \\(\\alpha! = \\Gamma(\\alpha + 1)\\), this still fails for negative integers since \\(\\Gamma\\) is not defined there); so we instead use this definition:Definition 1. The binomial coefficient \\(\\binom{\\alpha}{n}\\), where \\(\\alpha \\in \\mathbb{R}\\), is defined by\\[\\binom{\\alpha}{n} := \\frac{\\overbrace{\\alpha(\\alpha - 1)(\\alpha - 2)\\dotsb(\\alpha - n + 1)}^{n\\ \\text{terms}}}{n!}.\\]In the case that \\(\\alpha \\in \\mathbb{N}\\), this obviously agrees with the usual definition, as noted above. Let’s prove the binomial theorem using generating functions! The proof turns out to be quite interesting, and involves solving a differential equation!A generatingfunctionological proof of the binomial theoremFix \\(\\alpha \\in \\mathbb{R}\\) and let \\(A \\overset{\\text{ops}}{\\leftrightarrow} \\left(\\binom{\\alpha}{n}\\right)_n\\); this is the generating function of the binomial coefficients. Note that when \\(\\alpha \\in \\mathbb{N}\\), these terms eventually become 0, but usually we get infinitely many nonzero terms. Our goal is to show that \\(A = (1 + x)^\\alpha\\).Note that\\[\\frac{\\binom{\\alpha}{n}}{\\binom{\\alpha}{n + 1}} = \\frac{\\alpha(\\alpha - 1)\\dotsb(\\alpha - n + 1)}{\\alpha(\\alpha - 1)\\dotsb(\\alpha - n + 1)(\\alpha - n)} \\frac{(n + 1)!}{n!} = \\frac{n + 1}{\\alpha - n} \\implies (n + 1)\\binom{\\alpha}{n + 1} = (\\alpha - n)\\binom{\\alpha}{n};\\]this is a recurrence for the binomial coefficients that holds for \\(n \\geq 0\\), with \\(\\binom{\\alpha}{0} = \\frac{1}{0!} = 1\\), since 1 is the empty product.Now recall that if \\(A \\overset{\\text{ops}}{\\leftrightarrow} (a_n)\\), then \\(DA \\overset{\\text{ops}}{\\leftrightarrow} ((n + 1)a_{n + 1})\\); this is precisely the left hand side of our recurrence! In summary, and using rule 2 (on polynomials), we see\\[\\left((n + 1)\\binom{\\alpha}{n + 1}\\right)_n \\overset{\\text{ops}}{\\leftrightarrow} DA \\quad \\text{and} \\quad \\left((\\alpha - n)\\binom{\\alpha}{n}\\right)_n \\overset{\\text{ops}}{\\leftrightarrow} (\\alpha - xD)A.\\]So \\(DA = (\\alpha - xD)A \\implies (1 + x)DA = \\alpha A\\). This is a differential equation that the generating function for the binomial coefficients satisfy! We can use the theory of differential equations, in particular the integrating factor method (this is a first order linear ODE), to write this as\\[\\left(\\frac{1}{1 + x}\\right)^\\alpha DA - \\alpha \\left(\\frac{1}{1 + x}\\right)^{\\alpha + 1} A = 0\\]and observe that this gives\\[D\\left(\\left(\\frac{1}{1 + x}\\right)^\\alpha A\\right) = 0 \\implies \\left(\\frac{1}{1 + x}\\right)^\\alpha A = 1\\]where we use the initial condition \\(A(0) = \\binom{\\alpha}{0} = 1\\). Then rearranging, we see that\\[A = \\left(\\frac{1}{1 + x}\\right)^{-\\alpha} = (1 + x)^\\alpha,\\]and we are done – we have proved that\\[(1 + x)^\\alpha = \\sum_{n \\geq 0} \\binom{\\alpha}{n} x^n \\overset{\\text{ops}}{\\leftrightarrow} \\left(\\binom{\\alpha}{n}\\right)_n!\\]Applying the binomial theorem to the Catalan numbersRecall from the last post that Catalan numbers count, for instance, the number of ways to have a balanced string of parentheses of length \\(2n\\), e.g. something like (()(()))(()), but not ())((()). Then it turns out that \\(C_n = \\frac{1}{n + 1} \\binom{2n}{n}\\), and their generating function is\\[C = \\frac{1 - \\sqrt{1 - 4x}}{2x}.\\]Let’s use the binomial theorem with \\(\\alpha = 1/2\\), to recover the general formula for \\(C_n\\). This is useful, because for instance in the balanced parentheses problem, we can use a combinatorial argument to show that the generating function is \\(C\\), but a priori, we don’t know an explicit formula for \\(C_n\\) (or some similar problem).First recognise that\\[-C = \\frac{\\sqrt{1 - 4x} - 1}{2x} = \\frac{1}{x}\\left(\\frac{\\sqrt{1 - 4x}}{2} - \\frac{1}{2}\\right);\\]by the binomial theorem,\\[\\sqrt{1 - 4x} = (1 - 4x)^{1/2} = \\sum_{n \\geq 0} \\binom{1/2}{n} (-4x)^n = \\sum_{n \\geq 0} \\binom{1/2}{n} (-4)^n x^n\\]where \\(\\frac{1}{2}\\binom{1/2}{0}(-4)^0 = \\frac{1}{2}\\), so we recognise\\[-C \\overset{\\text{ops}}{\\leftrightarrow} \\left(\\frac{1}{2}\\binom{1/2}{n + 1}(-4)^{n + 1}\\right) \\implies C \\overset{\\text{ops}}{\\leftrightarrow} \\left(\\binom{1/2}{n + 1}(-1)^n 2^{2n + 1}\\right)\\]using rule 1 (with \\(m = 1\\)). Then it remains to check\\[\\begin{align*}C_n = [x^n]C &amp;amp;= \\binom{1/2}{n + 1}(-1)^n 2^{2n + 1} = \\frac{\\overbrace{(1/2)(-1/2)(-3/2)\\dotsb(-(2n-1)/2)}^{n\\ \\text{terms}}}{(n + 1)!}(-1)^n 2^{2n + 1} \\\\&amp;amp;= \\frac{1 \\cdot 3 \\cdot 5 \\dotsb (2n - 1)}{2^{n + 1} \\cdot (n + 1)!}2^{2n + 1} = \\underbrace{\\frac{2 \\cdot 4 \\cdot 6 \\dotsb 2n}{2^n \\cdot n!}}_{= 1} \\cdot \\frac{1 \\cdot 3 \\cdot 5 \\dotsb (2n - 1)}{(n + 1)!} 2^n \\\\&amp;amp;= \\frac{1}{n + 1} \\cdot \\frac{(2n)!}{(n!)^2} = \\frac{1}{n + 1}\\binom{2n}{n},\\end{align*}\\]which is the claimed formula for the Catalan numbers! OK, that’s enough for now; see you next year probably with my current rate of writing posts :P" }, { "title": "A generatingfunctionological proof of the geometric and arithmetic sequence formulas", "url": "/posts/generatingfunctionological-proof-geometric-arithmetic-sequences/", "categories": "Epic Maths Time, New Perspectives", "tags": "combinatorics, algebra, uni-maths", "date": "2022-04-16 11:28:00 +1000", "snippet": "Recall from high school that a geometric sequence is a sequence \\((a_n)_{n \\geq 0}\\) that satisfies the recurrence relation \\(a_{n + 1} = r a_n\\) for some fixed \\(r \\in \\mathbb{R}\\), and an arithmetic sequence is a sequence \\((b_n)_{n \\geq 0}\\) that satisfies \\(b_{n + 1} = b_n + d\\) for some fixed \\(d \\in \\mathbb{R}\\).For example, the sequences \\((1,2,4,8,16,\\dotsc)\\) and \\((1,-1,1,-1,1,\\dotsc)\\) are geometric, while the sequences \\((0,1,2,3,4,\\dotsc)\\) and \\((11,7,3,-1,-5,\\dotsc)\\) are arithmetic.You may recall, again from high school, the formulas\\[a_n = a_0 r^n \\quad \\text{and} \\quad b_n = b_0 + nd\\]for a generic term of the above geometric and arithmetic sequences, respectively.Exercise 1. Verify that the above two formulas for geometric and arithmetic sequences hold, using a proof by induction or similar approach.In this post, I will introduce a totally overkill approach of deriving these two formulas; this approach will turn out to be a general approach to solving many recurrence relations. The key to this approach is to use generating functions.A “naive” approach for geometric sequencesStarting with \\(a_{n + 1} = ra_n\\), multiply by \\(x^n\\) and sum over all \\(n \\geq 0\\) (for which this recurrence is valid for) to get\\[\\sum_{n \\geq 0} a_{n + 1}x^n = \\sum_{n \\geq 0} ra_n x^n = r \\sum_{n \\geq 0} a_n x^n.\\]If we let \\(A(x) = \\sum_{n \\geq 0} a_n x^n\\), then surely\\[\\sum_{n \\geq 0} a_{n + 1}x^n = \\sum_{n \\geq 1} a_nx^{n - 1} = \\frac{1}{x} \\sum_{n \\geq 1} a_nx^n = \\frac{1}{x} \\left(\\sum_{n \\geq 0} a_nx^n - a_0\\right) = \\frac{1}{x}(A(x) - a_0),\\]so we get the equation\\[\\frac{1}{x}(A(x) - a_0) = rA(x) \\implies A(x) = \\frac{a_0}{1 - rx} = a_0 \\sum_{n \\geq 0} (rx)^n = \\sum_{n \\geq 0} a_0 r^n x^n.\\]But recall that \\(A(x) = \\sum_{n \\geq 0} a_n x^n\\), so we must surely have \\(a_n = a_0 r^n\\), which agrees with the known formula!So we solved the recurrence relation by using some sort of magical overkill power series approach. How exactly does it work, can we be more methodical, and is it even useful? I will attempt to answer that in the rest of this post.Generating functionsUnless otherwise stated, all sequences \\((a_n)_{n \\geq 0} = (a_0,a_1,\\dotsc)\\) start with a zeroth term \\(a_0\\); I simply write \\((a_n)\\).Definition 1. Consider a sequence \\((a_n)\\). The (ordinary) generating function of \\((a_n)\\) is the (formal) power series\\[A = \\sum_{n \\geq 0}a_n x^n = a_0 + a_1x + a_2x^2 + \\dotsb\\]where the coefficient of \\(x^n\\), denoted \\([x^n]A\\), is precisely \\(a_n\\). We write \\((a_n) \\overset{\\text{ops}}{\\leftrightarrow} A\\).These power series are formal in the sense that we do not care about convergence: they are not analytic. In general, the \\(x\\) is to be interpreted as an indeterminate; a symbol that can be manipulated, but does not have meaning on its own. Representing a sequence in this way serves as to ensure that the terms in the sequence remain “separated” – they are separated by powers of \\(x\\).The ring of formal power seriesEvery formal power series is associated with a unique sequence – its sequence of coefficients – and vice versa. Two formal power series are equal if and only if the sequences of coefficients are equal.The set of formal power series forms a ring \\(\\mathbb{R}[[x]]\\) in a natural way (where the coefficients are in \\(\\mathbb{R}\\)); the addition is given by\\[\\left(\\sum_{n \\geq 0}a_n x^n\\right) + \\left(\\sum_{n \\geq 0}b_n x^n\\right) = \\sum_{n \\geq 0} (a_n + b_n)x^n,\\]and the (commutative) multiplication is given by\\[\\left(\\sum_{n \\geq 0}a_n x^n\\right)\\left(\\sum_{n \\geq 0}b_n x^n\\right) = \\sum_{n \\geq 0} \\left(\\sum_{k = 0}^n a_k b_{n - k}\\right)x^n;\\]this looks funny but it’s what we would expect when we try to multiply out an (infinite) expression of the form\\[(a_0 + a_1x + a_2x^2 + \\dotsb)(b_0 + b_1x + b_2x^2 + \\dotsb) = a_0b_0 + (a_0b_1 + a_1b_0)x + (a_0b_2 + a_1b_1 + a_2b_0)x^2 + \\dotsb\\]which it precisely is. The additive identity (zero) in \\(\\mathbb{R}[[x]]\\) is the power series \\(0 = 0 + 0x + 0x^2 + \\dotsb \\overset{\\text{ops}}{\\leftrightarrow} (0)\\). The multiplicative identity (unit) in \\(\\mathbb{R}[[x]]\\) is the power series \\(1 = 1 + 0x + 0x^2 + \\dotsb \\overset{\\text{ops}}{\\leftrightarrow} (1,0,0,\\dotsc)\\).For example, the (multiplicative) inverse of the power series \\(1 - x = 1 - x + 0x^2 + 0x^3 + \\dotsb\\) turns out to be \\(\\sum_{n \\geq 0}x^n = 1 + x + x^2 + \\dotsb\\); we can verify this by computing\\[(1 - x)(1 + x + x^2 + \\dotsb) = 1 + (1 - 1)x + (1 - 1 + 0)x^2 + \\dotsb = 1.\\]So it is reasonable to write that\\[\\frac{1}{1 - x} = \\sum_{n \\geq 0} x^n = 1 + x + x^2 + \\dotsb;\\]this is true in the formal sense, not just for \\(\\lvert x\\rvert &amp;lt; 1\\) as in the analytical case. However, when the power series in the analytical sense converges, it is reasonable to substitute in numerical values for \\(x\\). This also gives us our first (simple) result:Lemma 1. Let \\((1) = (1,1,\\dotsc)\\) be the constant sequence; then\\[\\frac{1}{1 - x} \\overset{\\text{ops}}{\\leftrightarrow} (1).\\]Note that extracting coefficients from power series is somehow “linear”, in the sense that \\([x^n](A + kB) = [x^n]A + k[x^n]B\\) (the formal power series also form a vector space over \\(\\mathbb{R}\\), and this is a linear map (functional) \\(\\mathbb{R}[[x]] \\to \\mathbb{R}\\)). This is a useful fact that we use later.Solving recurrences – a generatingfunctionological approachThroughout this section, let \\((a_n) \\overset{\\text{ops}}{\\leftrightarrow} A\\). A generatingfunctionological approach, as coined in Wilf’s book “generatingfunctionology”, is an approach to working with sequences using their generating functions.Definition 2. Let \\((a_n)\\) be a sequence. Then a (\\(k\\)th order) recurrence for \\((a_n)\\) is an equation \\(\\varphi(n,a_n,a_{n + 1},\\dotsc,a_{n + k}) = 0\\) which holds for particular \\(n\\).If we fix a value of \\(n\\), then a recurrence gives us one equation that \\((a_n)\\) satisfies. However, the expression\\[\\sum_n \\varphi(n,a_n,a_{n + 1},\\dotsc,a_{n + k})x^n = 0\\]simultaneously encodes every equation that \\((a_n)\\) satisfies that is given by the recurrence. In the (usual) case that \\(n\\) ranges over \\(\\mathbb{N}\\), we recover the generating function of \\((a_n)\\); otherwise observe for instance that \\(\\sum_{n \\geq N} a_n x^n = A - a_0 - a_1x - \\dotsb - a_{N - 1}x^{N - 1}\\).Thus, to solve a recurrence relation, we can attempt to convert the recurrence for \\((a_n)\\) into an equation involving its generating function \\(A\\) by finding the generating functions of the sequences equated in the recurrence; then if we can solve this for \\(A\\), then we have found \\(a_n = [x^n]A\\). However, we may not explicitly find \\(A\\) as a (formal) power series; using different techniques (such as partial fractions or the binomial theorem) we can find a power series expansion to extract the coefficients \\(a_n\\).A recurrence is linear if \\(a_{n + k} = f_0 a_n + f_1 a_{n + 1} + \\dotsb + f_{k - 1} a_{n + k - 1}\\) for some \\(k\\), where each \\(f_i\\), a coefficient, is a function of \\(n\\). We present a quick theorem without proof:Theorem 1. Let \\(A \\overset{\\text{ops}}{\\leftrightarrow} (a_n)\\). Then \\(A\\) is a rational function \\(p/q\\) (where \\(p,q\\) have lowest possible degree) with \\(\\deg q = k\\) if and only if \\((a_n)\\) satisfies a linear recurrence with constant coefficients of order \\(k\\).After reading this article, you will have the tools to prove this theorem yourself! (If you want to, of course!) One direction is by the technique for finding a generating function outlined below, and the other direction follows by considering an expansion of \\(q A = p\\).The algebra and calculus of generating functionsDefinition 3. The (formal) derivative of a power series \\(A = \\sum_{n \\geq 0} a_nx^n \\overset{\\text{ops}}{\\leftrightarrow} (a_n)\\) is the power series\\[DA = \\sum_{n \\geq 1} n a_n x^{n - 1} = \\sum_{n \\geq 0} (n + 1)a_{n + 1}x^n \\overset{\\text{ops}}{\\leftrightarrow} ((n + 1)a_{n + 1}).\\]The derivative operator \\(D\\) on \\(\\mathbb{R}[[x]]\\) is the map \\(A \\mapsto DA\\).We can verify some expected properties of the derivative operator: it is a derivation on \\(\\mathbb{R}[[x]]\\) (let \\(A,B \\in \\mathbb{R}[[x]]\\)), since It is linear (where we think of \\(\\mathbb{R}[[x]]\\) as a vector space): \\(D(A + kB) = DA + kDB\\) where \\(k \\in \\mathbb{R}\\), It satisfies a sort of (Leibniz) product rule: \\(D(AB) = A(DB) + (DA)B\\).Exercise 2. Check thse both! Remember to use the correct rule for multiplying power series for the product rule.We can also combine the derivative operator with other operators on \\(\\mathbb{R}[[x]]\\). For operators \\(S,T\\), define their sum \\(S + T\\) to be the map \\(A \\mapsto SA + TA\\) (pointwise addtion), and their product \\(ST\\) to be the map \\(A \\mapsto S(TA)\\) (composition of operators). The \\(k\\)th iterate of \\(T\\) is defined by \\(T^k := \\underbrace{TT\\dotsb T}_{k\\ \\text{copies}}\\), which is the map \\(A \\mapsto \\underbrace{T(T(\\dotsb(TA)\\dotsb))}_{k\\ \\text{times}}\\).Repeated differentiation is denoted by \\(D^k\\), i.e. \\(D^kA\\) is the \\(k\\)th (formal) derivative of \\(A\\). Another common operator that comes up when solving recurrences is the ecks dee xD operator \\(xD\\) on \\(\\mathbb{R}[[x]]\\), defined as the map \\(A \\mapsto xDA\\), i.e. differentiation then multiplication by \\(x\\). We often deal with polynomials in \\(xD\\), where \\(1\\) denotes the identity operator \\(A \\mapsto A\\), but note that \\((xD)^2 = xD(xD) \\neq x^2 D^2\\). Indeed,\\[(xD)^2 = xD(xD) = x(D + xD^2) = xD + x^2D^2 \\implies (xD)^2A = xDA + x^2D^2A\\]by the product rule. Furthermore, care must be taken as these operators do not generally commute: while \\(xD(xD + 1) = (xD)^2 + xD = (xD + 1)xD\\), note that \\(Dx \\neq xD\\) (we can think of $x$ as an operator on \\(\\mathbb{R}[[x]]\\) with \\(A \\mapsto xA\\); then \\(Dx1 = Dx = 1 \\neq 0 = xD1\\)). This is all related to the notion of a Weyl algebra, which is a ring of differential operators with polynomial coefficients (the addition is pointwise addition, and the product is composition of operators).Exercise 3. Similar to the above, what is an expansion of \\((xD)^k\\) without any powers of \\(xD\\)? (I haven’t tried this yet, but it looks promising.) Update (thanks Ally and Jacob): it looks like\\[(xD)^k = \\left\\{k \\atop 0\\right\\} + \\left\\{k \\atop 1\\right\\} xD + \\left\\{k \\atop 2\\right\\} x^2D^2 + \\dotsb + \\left\\{k \\atop k\\right\\} x^k D^k,\\]where\\[\\left\\{k \\atop n\\right\\} = \\frac{1}{n!} \\sum_{i = 0}^n (-1)^i \\binom{n}{i} (n - i)^k\\]are Stirling numbers of the 2nd kind, which count the number of ways to partition \\([n] = \\{1,\\dotsc,n\\}\\) into \\(k\\) (nonempty) parts. (Note that \\(\\left\\{k \\atop 0\\right\\} = 0\\) if \\(k \\geq 1\\), but \\(\\left\\{0 \\atop 0\\right\\} = 1\\), and \\((xD)^0 = 1 = \\operatorname{Id}_{\\mathbb{R}[[x]]}\\), so the pattern holds.) Prove/disprove this claim, and post your solutions in the unofficial Maths @ Monash Discord!Using these, we can identify some rules for the generating functions of some transformations of sequences:Lemma 2. Let \\((a_n) \\overset{\\text{ops}}{\\leftrightarrow} A\\) and \\((b_n) \\overset{\\text{ops}}{\\leftrightarrow} B\\). Then For any fixed \\(m &amp;gt; 0\\), \\((a_{n + m}) \\overset{\\text{ops}}{\\leftrightarrow} \\frac{1}{x^m}(A - a_0 - a_1x - \\dotsb - a_{m - 1}x^{m - 1})\\) If \\(p(n)\\) is any polynomial in \\(n\\), then \\(p(xD)A \\overset{\\text{ops}}{\\leftrightarrow} (p(n)a_n)\\) \\[AB \\overset{\\text{ops}}{\\leftrightarrow} \\left(\\sum_{k = 0}^n a_k b_{n - k}\\right)_n\\] For any \\(k \\in \\mathbb{R}\\), \\(A + kB \\overset{\\text{ops}}{\\leftrightarrow} (a_n + kb_n)\\) \\[\\frac{A}{1 - x} \\overset{\\text{ops}}{\\leftrightarrow} \\left(\\sum_{k = 0}^n a_k\\right)_n\\] For a fixed \\(k &amp;gt; 0\\), if \\(b_{kn} = a_n\\) for \\(n \\geq 0\\) and \\(b_m = 0\\) otherwise, then \\(A(x^k) = B(x) \\overset{\\text{ops}}{\\leftrightarrow} (b_n)\\)Note that in rule 1, we don’t mean division by \\(x^m\\) in the ring \\(\\mathbb{R}[[x]]\\), as it does not have an inverse. Rather, it is the quotient in an Euclidean division (note that \\(\\mathbb{R}[[x]]\\) is a Euclidean domain).We give a proof of rule 2; it suffices to prove it for monic monomials; then apply rule 4. Let \\(p(n) = n^k\\); then \\(p(xD)A = (xD)^kA\\). The case \\(k = 0\\) is trivial. Then if \\(k &amp;gt; 0\\), we proceed by induction on \\(k\\) and note that\\[p(xD)A = (xD)^kA = xD(xD)^{k - 1}A = xD \\sum_{n \\geq 0} n^{k - 1}a_n x^n = x \\sum_{n \\geq 1} n^ka_n x^{n - 1} = \\sum_{n \\geq 0} n^ka_n x^n \\overset{\\text{ops}}{\\leftrightarrow} (n^ka_n) = (p(n)a_n);\\]the 3rd equality is by the inductive hypothesis (i.e. that \\((xD)^{k - 1}A = \\sum_{n \\geq 0} n^{k - 1}a_n x^n \\overset{\\text{ops}}{\\leftrightarrow} (n^{k - 1}a_n)\\)). Thus we are done!Exercise 4. Prove the unproven generating function rules 1,3,4,5,6 above. (Hint for rule 5: use rule 3 and Lemma 1.) Post your solutions in the unofficial Maths @ Monash Discord!Finding formulas for the geometric and arithmetic sequencesUsing the algebra and calculus of generating functions, we give a succinct generatingfunctionological proof of the formulas for the geometric and arithmetic sequences.Recall that the geometric sequence \\((a_n)_{n \\geq 0}\\) satisfies \\(a_{n + 1} = r a_n\\). Let \\((a_n) \\overset{\\text{ops}}{\\leftrightarrow} A\\). Then by rule 1, \\((a_{n + 1}) \\overset{\\text{ops}}{\\leftrightarrow} \\frac{1}{x}(A - a_0)\\), so the recurrence (and rule 4) yields\\[\\frac{1}{x}(A - a_0) = rA \\implies A = \\frac{a_0}{1 - rx}.\\]Extracting coefficients and using (the surprise tool) linearity, we recover\\[a_n = [x^n]A = a_0[x^n]\\sum_{n \\geq 0}(rx)^n = a_0r^n.\\]Now, the arithmetic sequence \\((b_n)_{n \\geq 0}\\) satisfies \\(b_{n + 1} = b_n + d\\). Let \\((b_n) \\overset{\\text{ops}}{\\leftrightarrow} B\\). Then by rule 1, \\((b_{n + 1}) \\overset{\\text{ops}}{\\leftrightarrow} \\frac{1}{x}(B - b_0)\\); Lemma 1 and rule 4 yields \\((d) \\overset{\\text{ops}}{\\leftrightarrow} \\frac{d}{1 - x}\\), so the recurrence (and rule 4) yields (by partial fractions)\\[\\frac{1}{x}(B - b_0) = B + \\frac{d}{1 - x} \\implies B = \\frac{b_0 - d}{1 - x} + \\frac{d}{(1 - x)^2}.\\]By rule 2 with \\(p(n) = n\\), we have\\[xD\\frac{1}{1 - x} \\overset{\\text{ops}}{\\leftrightarrow} (p(n)1) = (n) \\implies \\frac{1}{(1 - x)^2} = \\frac{1}{x} \\left(xD\\frac{1}{1 - x} - 0\\right) \\overset{\\text{ops}}{\\leftrightarrow} (n + 1)\\]by rule 1. (There are other ways to do this, such as direct manipulation of the power series, but that’s boring!) Thus by linearity, we extract the coefficient\\[b_n = [x^n]B = (b_0 - d)[x^n]\\frac{1}{1 - x} + d[x^n]\\frac{1}{(1 - x)^2} = (b_0 - d)1 + d(n + 1) = b_0 + dn\\]since \\((1) \\overset{\\text{ops}}{\\leftrightarrow} \\frac{1}{1 - x}\\) and \\((n + 1) \\overset{\\text{ops}}{\\leftrightarrow} \\frac{1}{(1 - x)^2}\\) (recall what this means). This is the formula for the arithmetic sequence; how awesome! (OK that was totally overkill LOL.)Exercise 5. Show that\\[\\frac{1}{(1 - x)^2} \\overset{\\text{ops}}{\\leftrightarrow} (n + 1)\\]in the following alternative ways: Use the fact that \\(\\frac{1}{(1 - x)^2} = D\\frac{1}{1 - x}\\), and explicitly differentiating the power series \\(\\sum_{n \\geq 0} x^n\\) and identifying the coefficient that appears. Use the fact that \\(\\frac{1}{(1 - x)^2} = D\\frac{1}{1 - x}\\) again, but look at the comment in Definition 3 (i.e. that \\(DA \\overset{\\text{ops}}{\\leftrightarrow} ((n + 1)a_{n + 1}).\\) if \\(A \\overset{\\text{ops}}{\\leftrightarrow} (a_n)\\); choose \\((a_n)\\) carefully). Use fact 5 repeatedly, starting from $A = 1$. (What sequence is this the generating function of?)Post your solutions in the unofficial Maths @ Monash Discord!A few more applications (an outline only)There are many nice applications of this generatingfunctionological technique. Here are just a few: The Fibonacci sequence \\((F_n)\\) satisfies the linear recurrence \\(F_{n + 2} = F_{n + 1} + F_n\\) for \\(n \\geq 0\\) with \\(F_0 = 0\\) and \\(F_1 = 1\\). It has generating function \\(F = \\frac{x}{1 - x - x^2}\\); we can recover a formula for \\(F_n\\) using partial fractions. The binomial theorem \\((1 + x)^\\alpha = \\sum_{n \\geq 0} \\binom{\\alpha}{n} x^n \\overset{\\text{ops}}{\\leftrightarrow} \\left(\\binom{\\alpha}{n}\\right)_n\\) where \\(\\alpha \\in \\mathbb{R}\\). I talk about this in more detail in the next post! The Catalan numbers \\(C_n = \\frac{1}{n + 1} \\binom{2n}{n}\\) have generating function \\(C = \\frac{1 - \\sqrt{1 - 4x}}{2x}\\); using the binomial theorem with \\(\\alpha = 1/2\\), we can recover this formula for \\(C_n\\). Moreover, they satisfy the recurrence \\(C_{n + 1} = \\sum_{i = 0}^n C_i C_{n - i}\\) with \\(C_0 = 1\\); note that \\(\\left(\\sum_{i = 0}^n C_i C_{n - i}\\right) \\overset{\\text{ops}}{\\leftrightarrow} C^2\\) by rule 3, so \\(\\frac{1}{x}(C - 1) = \\frac{1}{x}(C - C_0) = C^2 \\iff C - 1 = xC^2\\), which can be used to find \\(C\\) as before (use the initial condition \\(C_0 = 1\\) to pick the negative square root). Note that \\(C_n\\) is, for instance, the number of ways to have a balanced string of parentheses of length \\(2n\\), e.g. something like (()(()))(()), but not ())((()).Exercise 6. (Adapted from discussion on the Maths @ Monash Discord server.) Consider the triangular numbers \\(T_n = \\frac{n(n + 1)}{2}\\), and define a recurrence \\(a_{n + 1} = a_n + T_n\\), with \\(a_0 = 0\\). Find a linear recurrence with constant coefficients that \\((a_n)\\) satisfies (consider Theorem 1 above), and use a generatingfunctionological approach to find an explicit formula for \\(a_n\\) (feel free to use a computer to find a series expansion). Post your solutions in the unofficial Maths @ Monash Discord!Happy generatingfunctionologing (and happy Easter too $xD$)!" }, { "title": "Integrating rational functions, partial fractions, and a taste of algebra, part 2", "url": "/posts/integrating-rational-functions-2/", "categories": "Epic Maths Time, Cool Stuff", "tags": "algebra, calculus, rings, polynomials, uni-maths", "date": "2021-06-29 15:42:00 +1000", "snippet": "Make sure you read part 1 first! Recall that we were exploring integrating rational functions, and to do so, we needed to look at partial fraction decompositions. As we now begin to discuss that in detail, we first look more closely at polynomial rings (over fields).Polynomial rings over fieldsPolynomial division with remainder, and the factor theoremEvaluating polynomials in (extension) fieldsConjugate root theorem for real polynomialsComplete factorisation of real polynomialsTheorem. Every real polynomial \\(p \\in \\mathbb R[\\mathrm x]\\) can be factorised over \\(\\mathbb R\\) into a product of linear and irreducible quadratic factorsExistence and uniqueness of partial fraction decompositionsIt also works over any Euclidean domain!!Partial fractions for the rationals: an algorithmSolving the original problem: integrating rational functionsTo be continued…" }, { "title": "Integrating rational functions, partial fractions, and a taste of algebra, part 1", "url": "/posts/integrating-rational-functions/", "categories": "Epic Maths Time, Cool Stuff", "tags": "algebra, calculus, rings, polynomials, uni-maths", "date": "2021-06-29 15:42:00 +1000", "snippet": "You know how to integrate a polynomial:\\[\\int (a_0 + a_1x + \\dotsb + a_nx^n) \\,dx = C + a_0x + \\frac{a_1}{2}x^2 + \\dotsb + \\frac{a_n}{n + 1}x^{n + 1},\\]where \\(C \\in \\mathbb R\\) is a real constant. But what about a rational function \\(\\frac{p}{q}\\) where \\(p,q\\) are polynomials? Is the indefinite integral\\(\\int \\frac{p(x)}{q(x)}\\,dx\\)a family of elementary functions? It turns out that it is — that is, in theory at least, we can take any rational function and write its integral explicitly using “nice” functions (namely other rational functions, logarithms, and arctangents).The key idea is to use polynomial division with remainder, and partial fraction decomposition. It might be obvious what the solution is now, but not so fast: have you ever thought about how and why partial fractions work? And can we do it without complex numbers in the (result of the) integral? Must the coefficients be real, or can they be complex too? And does this process perhaps… generalise? We will answer these questions (and more), by delving into the mysterious world of abstract algebra. (This will probably be the first of many posts on algebra, which is a field of maths that is close to my heart.)A quick recap on partial fractionsYou may have previously learnt partial fractions to solve the problem of integrating certain rational functions (or simply plotting rational functions). More or less, the process looks like the following: we have a rational function (a quotient of polynomials)\\[\\frac{p(x)}{q(x)}\\]where the degree of \\(p\\) is strictly less than the degree of \\(q\\). We then factorise \\(q\\) into\\[q(x) = q_1(x)^{a_1} q_2(x)^{a_2} \\dotsb q_k(x)^{a_k}\\]where typically the \\(q_i\\) are irreducible in the sense that there are no nontrivial factorisations of \\(q_i\\) into a product of lower degree polynomials (and each \\(a_i \\in \\mathbb Z^+\\)). Then we can write\\[\\frac{p(x)}{q(x)} = \\sum_{j = 1}^{a_1} \\frac{p_{1j}(x)}{q_1(x)^j} + \\sum_{j = 1}^{a_2} \\frac{p_{2j}(x)}{q_2(x)^j} + \\dotsb + \\sum_{j = 1}^{a_k} \\frac{p_{kj}(x)}{q_k(x)^j}\\]where \\(\\deg p_{ij} &amp;lt; \\deg q_i\\) for all \\(i,j\\).For example, for given \\(a,b,c,d,e \\in \\mathbb R\\), we may decompose\\[\\frac{ax^4 + bx^3 + cx^2 + dx + e}{x(x - 1)^2(x^2 + x + 1)} = \\frac{A}{x} + \\frac{B}{x - 1} + \\frac{C}{(x - 1)^2} + \\frac{Dx + E}{x^2 + x + 1}.\\]A usual technique is, once we have the correct form of the partial fraction decomposition, we cross-multiply to yield\\[ax^4 + bx^3 + cx^2 + dx + e = A(x - 1)^2(x^2 + x + 1) + Bx(x - 1)(x^2 + x + 1) + Cx(x^2 + x + 1) + (Dx + E)x(x - 1)^2,\\]which, considering as an equation in \\(\\mathbb R_4[x]\\) (the vector space of real polynomials of degree at most 4) and explicitly rewriting the right-hand side as a linear combination of basis polynomials \\(x^4,x^3,x^2,x,1\\), allows us to compare coefficients and form a system of 5 equations in 5 variables, which must be consistent (as we will see in the existence of decomposition proof). Gaussian elimination (or another approach) then yields the unique coefficients \\(A,B,C,D,E \\in \\mathbb R\\), at which point we have found the partial fraction decomposition.Partial fractions for… fractions?Partial fractions for rational functions is something that most people have studied. But you may be more surprised to find out that the same process works if we replace the real number polynomial coefficients with any other field (essentially a set with addition and multiplication, where you can divide by anything nonzero), e.g. the complex numbers, rationals, or integers modulo a prime! Perhaps even more surprisingly, we can do partial fractions for the rational numbers \\(\\mathbb Q\\).What exactly do I mean? We start off with a proper fraction (numerator is less than denominator). We can let prime numbers take the place of irreducible (quadratic and linear) polynomials on the denominators, and instead of the condition that the degree of the numerator is strictly less than that of the irreducible polynomial in the denominator, we require that the absolute value of the numerator is strictly less than that of the prime in the denominator. For example, I calculated that\\[\\frac{37}{300} = \\frac{1}{2} + \\frac{1}{2^2} + \\frac{1}{3} - \\frac{4}{5} - \\frac{4}{5^2}.\\]Why should this be the correct generalisation? In the proof of the existence of a partial fraction decomposition, we will see that we don’t need to explicitly assume we are working with polynomials. In fact, the same argument works for any Euclidean domain, which is, roughly speaking, a set with addition, multiplication, and a null factor law, where we can also perform division with remainder (with a notion of size called a valuation). For real polynomials (which are building blocks of rational functions), the valuation is the degree function, but in the integers (which are building blocks of the rationals), a valuation is the absolute value function. The notion of an Euclidean domain is abstract algebraic, but allows us to abstract away from a concrete construction and prove results simultaneously for a general class of objects; furthermore, the algorithm in each Euclidean domain is identical, up to the actual division with remainder algorithm. And this is just a taste of the power of abstract algebra.Rings, fields, and Euclidean domainsThis section will be a self-contained brief introduction to the relevant ring theory required for the proof. It may seem very definition heavy, and if you cannot follow, feel free to skip (at your own risk) to part 2. We firstly define rings.Definition 1. A binary operation on a set \\(X\\) is a map \\(f : X \\times X \\to X\\) from the Cartesian product. It takes in two elements of \\(X\\), and returns a single element, also in \\(X\\). We often write \\(f(x,y) = x * y\\).Some properties of a binary operation \\(* : X \\times X \\to X\\) may include: Commutativity: for all \\(x,y \\in X\\), \\(x * y = y * x\\). (Order doesn’t matter.) Associativity: for all \\(x,y,z \\in X\\), \\((x * y) * z = x * (y * z)\\). (Brackets don’t matter.) Identity: there is an \\(e \\in X\\) such that \\(e * x = x * e = x\\) for all \\(x \\in X\\). (Applying \\(e\\) doesn’t do anything.) Inverses: if \\(e\\) is the identity, then for any \\(x \\in X\\), there exists \\(y \\in X\\) such that \\(x * y = y * x = e\\). (You can undo everything.)For example, addition on \\(\\mathbb R\\) (but also \\(\\mathbb Z,\\mathbb Q,\\mathbb C\\)) satisfies all 4 above criteria, with identity \\(e = 0\\) and inverse \\(y = -x\\) for \\(x \\in \\mathbb R\\). (However, inverses is not satisfied if we take addition on \\(\\mathbb N\\); 1 has no inverse.) Multiplication (on \\(\\mathbb R\\)) is commutative, associative, and has identity \\(1\\). Subtraction is a binary operation, but is neither commutative nor associative, and has no identity! (Can you see why?)Challenge question 1. Prove that on \\(\\mathbb R\\), subtraction is a binary operation that is not commutative, associative, and has no identity. Identify which of division on \\(\\mathbb R\\), exponentiation on \\(\\mathbb R^+\\), maximum on \\(\\mathbb R\\), and greatest common divisor on \\(\\mathbb Z^+\\) are binary operations, and which of the above properties they possess (if they are binary operations). Post your solutions in the unofficial Maths @ Monash Discord!Definition 2. A (unital) ring \\((R,+,{\\cdot})\\) is a set \\(R\\) with two binary operations \\(+\\) (addition) and \\(\\cdot\\) (multiplication), satisfying: (A1) Addition is commutative (A2) Addition is associative (A3) Addition has an identity, \\(0\\) (called zero) (A4) Each element \\(r \\in R\\) has an inverse under addition, \\(-r\\) (called the negative) (M1) Multiplication is associative (M2) Multiplication has an identity, \\(1\\) (called unity) (AM) Multiplication distributes over addition: for \\(r,s,t \\in R\\), \\(r \\cdot (s + t) = (r \\cdot s) + (r \\cdot t)\\) and \\((r + s)\\cdot t = (r \\cdot t) + (s \\cdot t)\\)Properties (A1)–(A4) imply \\((R,+)\\) is an abelian group. Property (AM) implies multiplication and addition interact nicely. These properties are often called axioms. Additionally, multiplication takes precedence over addition, i.e. \\(r \\cdot s + t = (r \\cdot s) + t\\) and \\(r + s \\cdot t = r + (s \\cdot t)\\). (We often drop the \\(\\cdot\\) when performing multiplication, and write \\(rs = r \\cdot s\\).) Rings in which multiplication is also commutative are the creatively-named commutative rings.Some examples of (unital) rings include \\(\\mathbb R,\\mathbb C,\\mathbb Q,\\mathbb Z\\) under the usual addition and multiplication (with zero \\(0\\) and unity \\(1\\)), continuous functions under the usual pointwise addition and multiplication, the set of \\(n \\times n\\) square matrices \\(M_n(R)\\) over a ring \\(R\\) (with zero the zero matrix, and unity the identity matrix with the unity from \\(R\\) down the diagonal and zeroes elsewhere; here, multiplication is not commutative!), and polynomial rings (which we discuss later).Definition 3. A unit in a (unital) ring (with unity \\(1\\)) is an element \\(u \\in R\\) such that there exists \\(v \\in R\\) with \\(uv = vu = 1\\); then \\(v = u^{-1}\\) is a (multiplicative) inverse of \\(u\\). The set of units in \\(R\\) is denoted \\(R^*\\); it is a group (it satisfies precisely (A2)–(A4) plus closure, but for multiplication instead), called the unit group.Challenge question 2. Prove, using the axioms only, that the zero \\(0\\) and unity \\(1\\) are unique in a ring. Thus prove that if additive or multiplicative inverses exist, then they are unique. Prove that \\(R^* := \\{u \\in R : u\\ \\text{is a unit}\\}\\) forms a group under multiplication from \\(R\\). (That is, multiplication is a binary operation (i.e. the product of two units is a unit), it is associative, has an identity, and every element has an inverse.)Challenge question 3. Let us consider the ring of \\(2 \\times 2\\) integer matrices \\(M_2(\\mathbb Z)\\), endowed with the usual addition and multiplication of square matrices (from say \\(M_2(\\mathbb R)\\)). Argue that if\\[A = \\begin{pmatrix} a &amp;amp; b \\\\ c &amp;amp; d \\end{pmatrix} \\in M_2(\\mathbb Z)\\] has a (multiplicative) inverse \\(A^{-1} \\in M_2(\\mathbb Z)\\) such that \\(AA^{-1} = A^{-1}A = I\\) (where \\(I\\) is the usual \\(2 \\times 2\\) identity matrix), then \\(A^{-1} = \\frac{1}{ad - bc} \\begin{pmatrix} d &amp;amp; -b \\\\ -c &amp;amp; a \\end{pmatrix} \\in M_2(\\mathbb R)\\). Thus conclude that \\(A \\in M_2(\\mathbb Z)\\) has an inverse if and only if \\(\\det A \\in \\{\\pm 1\\} = \\mathbb Z^*\\). This proves that the unit group is \\(GL_2(\\mathbb Z) := (M_2(\\mathbb Z))^* = \\{A \\in M_2(\\mathbb Z) : \\det A = \\pm 1\\}\\). Use this to conjecture what \\(GL_n(\\mathbb Z) := (M_n(\\mathbb Z))^*\\) is, for any integer \\(n \\geq 1\\). Prove that for any commutative (unital) ring \\(R\\) (where multiplication is commutative), \\(GL_2(R) := (M_2(R))^* = \\{A \\in M_2(R) : \\det A \\in R^*\\}\\), where the determinant is defined as usual. This is the general linear group: the set of invertible matrices with entries in \\(R\\). (Compare this to what you know when \\(R = \\mathbb R\\) or \\(\\mathbb C\\).)Post your solutions in the unofficial Maths @ Monash Discord!Fields, division rings, and the quaternionsDefinition 4. A field \\(K\\) is a commutative (unital) ring such that \\(K^* = K \\setminus \\{0\\}\\), that is, every nonzero element has a (multiplicative) inverse. (It follows that \\(K \\setminus \\{0\\}\\) is an abelian group under multiplication.)Some examples of fields include \\(\\mathbb R,\\mathbb C,\\mathbb Q\\), and also the integers modulo \\(p\\) where \\(p\\) is prime: \\(\\mathbb Z_p\\). Fields are also the building blocks of linear algebra: the scalars in a vector space belong to a field. If we remove the condition that the ring is commutative (but maintain the requirement that \\(F^* = F \\setminus \\{0\\}\\)), we get a skew-field or division ring: a prominent example is \\(\\mathbb H\\), the quaternions, which is a 4-dimensional \\(\\mathbb R\\)-vector space with (abstract) basis elements \\(1,i,j,k\\) with multiplication satisfying \\(1\\alpha = \\alpha 1 = \\alpha\\) and \\(\\lambda\\alpha = \\alpha\\lambda\\) for all \\(\\alpha \\in \\mathbb H\\) and \\(\\lambda \\in \\mathbb R\\), and\\[i^2 = j^2 = k^2 = ijk = -1.\\]Challenge question 4. We work with the quaternions \\(\\mathbb H\\). Recall that we define multiplication so that it is a ring (it is associative, and distributes over addition). Show that \\(ij = k\\), \\(jk = i\\), \\(ki = j\\), \\(ji = -k\\), \\(kj = -i\\), and \\(ik = -j\\). (Think of this with \\(ijk\\) written cyclically, with a negative sign if we go backwards.) What is \\(i^{-1}\\), \\(j^{-1}\\), and \\(k^{-1}\\)? For \\(\\alpha = a + bi + cj + dk \\in \\mathbb H\\) (where \\(a,b,c,d \\in \\mathbb R\\)), define \\(\\bar\\alpha = a - bi - cj - dk\\). Define the norm \\(\\lvert\\alpha\\rvert = \\sqrt{\\alpha\\bar \\alpha}\\). Show that \\(\\lvert\\alpha\\rvert^2 \\in \\mathbb R_{\\geq 0}\\) (using distributive laws and part 1), so that this makes sense. Prove that \\(\\lvert\\alpha\\beta\\rvert = \\lvert\\alpha\\rvert \\lvert\\beta\\rvert\\) for \\(\\alpha,\\beta \\in \\mathbb H\\), and that \\(\\lvert\\alpha\\rvert = 0\\) if and only if \\(\\alpha = 0\\). (Hint: show that \\(\\lvert\\alpha\\beta\\rvert^2 = \\lvert\\alpha\\rvert^2 \\lvert\\beta\\rvert^2\\).) If \\(\\alpha \\neq 0\\), Let \\(\\beta = \\bar\\alpha/\\lvert\\alpha\\rvert^2 \\in \\mathbb H\\). What is \\(\\alpha\\beta\\) and \\(\\beta\\alpha\\)? Thus conclude that \\(\\mathbb H^* = \\mathbb H \\setminus \\{0\\}\\), i.e. that \\(\\mathbb H\\) is a division ring.Post your solutions in the unofficial Maths @ Monash Discord!Definition 5. A subset \\(S \\subseteq R\\) is a subring of a ring \\((R,+,\\cdot)\\) if \\((S,+,\\cdot)\\) is a ring, when the binary operations are restricted to \\(S\\) (in particular, must be maps \\(S \\times S \\to S\\)). Replacing “ring” with “field”, we get the notion of a subfield.Euclidean domains and the Euclidean algorithmDefinition 6. An Euclidean domain (ED) is a commutative (unital) ring \\(R\\) with a valuation (or Euclidean function) \\(\\nu : R \\setminus \\{0\\} \\to \\mathbb N\\) such that: (No zero divisors) if \\(ab = 0\\) for \\(a,b \\in R\\), then \\(a = 0\\) or \\(b = 0\\) (so that it is an integral domain), (Division with remainder) if \\(a,b \\in R\\) with \\(b \\neq 0\\), there exist \\(q,r \\in R\\) with \\(a = qb + r\\) with \\(\\nu(r) &amp;lt; \\nu(b)\\) or \\(r = 0\\), if \\(a,b \\in R\\) with \\(a,b \\neq 0\\), then \\(\\nu(a) \\leq \\nu(ab)\\).In particular, \\(\\mathbb Z\\) is an Euclidean domain with valuation \\(\\nu(z) = \\lvert z \\rvert\\). So are the Gaussian integers, \\(\\mathbb Z[i] := \\{a + bi : a,b \\in \\mathbb Z\\}\\) with valuation \\(\\nu(a + bi) = a^2 + b^2\\). So is any field \\(K\\), with valuation \\(\\nu(\\alpha) = 1\\). (As we will shortly see, and as may be suggestive, polynomial rings over fields are also Euclidean domains with the degree as the valuation!)In Euclidean domains (and in integral domains), we have a notion of divisibility, and a notion of primality: irreducibility.Definition 7. If \\(R\\) is an ED and \\(a,b \\in R\\), then \\(a\\) divides \\(b\\) (and \\(a\\) is a divisor of \\(b\\)), written \\(a \\mid b\\), if there is \\(k \\in R\\) such that \\(b = ka\\).Definition 8. If \\(r = ab\\) implies \\(a\\) or \\(b\\) is a unit (in \\(R^*\\)), then \\(r\\) is irreducible. Otherwise, it is reducible, and there are non-units \\(a,b\\) with \\(r = ab\\). This is essentially a nontrivial factorisation.The definition of irreducible looks very much like the definition of a prime in \\(\\mathbb N\\) (or \\(\\mathbb Z\\)). In fact, it is precisely the same definition: it essentially says that if \\(p = ab\\) implies \\(a = 1\\) or \\(b = 1\\) (over \\(\\mathbb N\\)), then \\(p\\) is prime, which essentially is the usual definition. In Euclidean domains (and integral domains), there is another notion or prime element: one such that \\(p \\mid ab\\) implies \\(p \\mid a\\) or \\(p \\mid b\\). It turns out that they are equivalent to irreducible elements in EDs! Moreover, in Euclidean domains, we have an analogue of the fundamental theorem of arithmetic that holds:Theorem 9. Every Euclidean domain has unique factorisation into irreducibles: if \\(a \\in R\\) is nonzero and not a unit, then there are irreducible elements \\(p_1,...,p_r \\in R\\) such that \\(a = p_1p_2 \\dotsb p_r\\). Moreover, this representation is unique up to multiplication (of each irreducible) by units.For example, in \\(\\mathbb Z\\), we know that \\(12 = 2 \\cdot 2 \\cdot 3\\). But we may also write \\(12 = 2 \\cdot (-2) \\cdot (-3)\\); we note that \\(-2 = (-1) \\cdot 2\\) and \\(-3 = (-1) \\cdot 3\\), which is multiplication by the unit \\(-1\\). There is no way to factorise \\(12\\) into primes a completely different way. Now, in \\(\\mathbb R[x]\\) (polynomials with real coefficients), we may write \\(2x^2 + 10x + 12 = (x + 2)(2x + 6) = (2x + 4)(x + 3)\\); note that the irreducible linear terms in these two expressions only differ by muliplying/dividing by the unit \\(2\\).We are ready for the Euclidean algorithm. Recall that in the integers, it provides us a way to find the greatest common divisor of two integers, using division with remainder. This suggests that the Euclidean algorithm may also work in Euclidean domains… but first, what even is a greatest common divisor?Definition 10. if \\(R\\) is an ED and \\(a,b \\in R\\), an element \\(d \\in R\\) is a common divisor of \\(a\\) and \\(b\\) if \\(d \\mid a\\) and \\(d \\mid b\\). A greatest common divisor (gcd) of \\(a\\) and \\(b\\) is an common divisor \\(g \\in R\\) of \\(a,b\\), such that for all common divisors \\(d\\) of \\(a,b\\), we have \\(d \\mid g\\).Greatest common divisors are not unique in general, but are unique up to units: \\(g\\) is a gcd of \\(a,b\\) if and only if \\(ug\\) is a gcd of \\(a,b\\) for some unit \\(u \\in R^*\\). For example, \\(6\\) is a gcd of \\(12\\) and \\(18\\), but so is \\(-6\\). \\(x + 3\\) is a gcd of \\((x + 2)(x + 3),(x - 4)(x + 3) \\in \\mathbb R[x]\\), but so is \\(2x + 6\\): note that \\((x + 2)(x + 3) = (\\frac{1}{2}x + 1)(2x + 6)\\) and \\((x - 4)(x + 3) = (\\frac{1}{2}x - 2)(2x + 6)\\).Algorithm 10 (Euclidean algorithm).Valuations, gcds, Euclidean algorithm, etcTo be continued…Make sure you read part 2, which can be found here soon." }, { "title": "An interactive visualisation of immersed surfaces on Desmos", "url": "/posts/desmos-3d-plotter/", "categories": "Epic Maths Time, Cool Stuff", "tags": "differential-geometry, linear-algebra, uni-maths", "date": "2021-06-20 00:40:00 +1000", "snippet": "Note: this article is currently a WIP.Some examples of surface visualisationsHere are a couple of versions of the Desmos save file with different cool pre-loaded plots: The default: a hemisphere (select the second plot for a full sphere) A mobius band A heliocoid An immersed Klein bottle in \\(\\mathbb R^3\\) (thanks to cFOURbon for entering the formula) A heart-shaped surface A shell (thanks to Kevin D. for the help and idea) Give me my chemistry degree immediately?Note: The below was submitted as my essay for the final assignment in the unit MTH3110 - differential geometry, at Monash University, in Semester 1, 2021. I’ve chosen to upload it here for those who may have seen my Desmos surface visualisation, and are interested in how I derived it! However, it assumes familiarity, especially near the end, with differential-geometric quantities such as maps of surfaces and their derivatives, and tangent spaces.The explanation and geometry of the Desmos visualisationHere is an interactive visualisation of surfaces on Desmos (a graphing website), made by me. It takes a (continuous) function \\(f : U \\to \\mathbb R\\), for some \\(U \\subseteq \\mathbb R^2\\), and plots a projection of the graph of \\(f\\) onto \\(\\mathbb R^2\\) as a “wire-frame”; it can also take a parametrisation \\(\\sigma : U \\to \\mathbb R^3\\) and plot a projection of its image in the plane.1 We discuss the algebra and geometry used in its construction, and some geometric properties of the projection map. Henceforth, let us assume that \\(U\\) is open, \\(f\\) is a smooth function, and that \\(\\sigma\\) is a regular surface patch.Projecting down to a planeThere are many ways to project \\(\\mathbb R^3\\), onto \\(\\mathbb R^2\\). However, a way to choose a sensible, well-behaved projection is to choose a plane \\(\\Pi\\) through the origin (a linear subspace of \\(\\mathbb R^3\\)), and perform an orthogonal projection \\(\\pi&#39;\\). Such a plane can be uniquely determined by using spherical coordinates. Consider an “observer” at \\(N \\in S^2\\), the unit sphere, and a standard map \\(\\tau : \\mathbb R^2 \\to S^2\\) given by\\[\\tau(u,v) = (\\cos u\\cos v,\\cos u\\sin v,\\sin u);\\]here, \\((u,v)\\) respectively measure latitude and longitude.2 The unit vectors in \\(T_0\\mathbb R^3\\) (denoting possible directions from the origin) are precisely points on \\(S^2\\). Thus, we may take \\(\\Pi\\) as the orthogonal complement of the span of \\(\\{N\\}\\).A fact from differential geometry is that \\(T_N S^2 = \\{v \\in \\mathbb R^3 : N \\cdot v = 0\\}\\). If \\(v \\in \\Pi\\), then for any \\(kN \\in \\operatorname{span}\\{N\\}\\) (where \\(k \\in \\mathbb R\\)), \\((kN) \\cdot v = k(N \\cdot v) = 0\\). In particular, \\(N \\cdot v = 0\\), so \\(v \\in T_NS^2\\). Conversely, a vector \\(v \\in T_NS^2\\) satisfies \\((kN) \\cdot v = k(N \\cdot v) = 0\\) for all \\(k \\in \\mathbb R\\), so \\(v \\in \\Pi\\). This means that \\(\\Pi = T_NS^2\\), and \\(N\\) is normal to this tangent space.Next, we consider the problem of projecting from \\(\\mathbb R^3\\) into \\(\\Pi\\) (and then into \\(\\mathbb R^2\\)). Given an orthonormal basis \\(b = \\{b_1,b_2\\}\\) for \\(\\Pi\\) that extends to a right-handed orthonormal basis \\(b&#39; = \\{b_1,b_2,N\\}\\) of \\(\\mathbb R^3\\), where \\(N = b_1 \\times b_2\\), consider the orthogonal projection \\(\\pi&#39; : \\mathbb R^3 \\to \\Pi\\). Since \\(\\ker\\pi&#39; = \\Pi^\\perp\\) and \\(\\pi\\vert_\\Pi\\) is the identity, it follows that \\(\\pi&#39;(b_1) = b_1\\), \\(\\pi&#39;(b_2) = b_2\\), and \\(\\pi&#39;(N) = 0\\). The map \\(\\pi&#39;\\) is linear, so its matrix with respect to the bases \\(b&#39;,b\\) is\\[\\pi&#39;_{b&#39;,b} =\\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0 \\\\ 0 &amp;amp; 1 &amp;amp; 0\\end{pmatrix}.\\]The geometry of this map is as follows: take a point \\(p \\in \\mathbb R^3\\). Then the coset \\(p + \\Pi^\\perp = \\{p + kN : k \\in \\mathbb R\\}\\), a line parallel to \\(N\\) (thus orthogonal to \\(\\Pi\\)) passing through \\(p\\), is collapsed onto a point \\(\\pi&#39;(p) \\in \\Pi\\); distinct parallel lines are collapsed to distinct points. This is an orthographic projection, where the axes are not foreshortened, that is, no length distortion due to perspective (see Figure~\\mathbb Ref{fig:cylinder_perspective}).\\footnote{See explanation of perspective and foreshortening in art.} Under this projection, we consider \\(\\mathbb R^3\\) as the quotient \\(\\mathbb R^3/\\Pi^\\perp\\), and cannot distinguish between points on the same line parallel to \\(\\Pi^\\perp\\); the map has rank \\(2\\) and nullity \\(1\\).\\begin{figure}[p!]\\centering\\includegraphics[width=0.75\\textwidth]{cylinderperspective.png}\\caption{Plot of cylinder \\(\\sigma : (0,2\\pi) \\times (-4,4) \\to S\\), \\(\\sigma(u,v) = (v,\\cos u,\\sin v)\\) with perspective \\((\\theta,\\phi) = (0.1,-0.1)\\), using the Desmos visualisation. Observe that there is no distortion due to perspective (i.e. _foreshortening) in the negative \\(x\\)-direction.}\\label{fig:cylinder_perspective}\\end{figure}Next, we consider the map that transforms points on \\(\\Pi\\) into points in \\(\\mathbb R^2\\). Given our basis \\(b\\) for \\(\\Pi\\), there is a natural sense in which \\(b_1\\) can be thought of as pointing “right”, and \\(b_2\\) as pointing “up”. This is described by \\(T : \\Pi \\to \\mathbb R^2\\), the linear isometry such that \\(T(b_1) = e_1\\) and \\(T(b_2) = e_2\\). Letting \\(e&#39; = \\{e_1,e_2\\} \\subseteq \\mathbb R^2\\), \\(T\\) is simply the identity in coordinates \\(b,e&#39;\\): \\(T_{b,e&#39;} = I_2\\), the \\(2 \\times 2\\) identity matrix.Thus, our overall projection \\(\\pi : \\mathbb R^3 \\to \\mathbb R^2\\) in the direction of \\(\\Pi\\) would be given by \\(\\pi = T \\circ \\pi&#39;\\), with matrix \\(T_{b,e&#39;} \\pi&#39;_{b&#39;,b}\\). However, we wish to express the matrix for \\(\\pi\\) with respect to the standard basis \\(e = \\{e_1,e_2,e_3\\}\\) for \\(\\mathbb R^3\\). For this, we recall that the change-of-basis matrix from \\(b&#39;\\) to \\(e\\) is given by\\[M_{b&#39; \\to e} =\\begin{pmatrix} \\vert &amp;amp; \\vert &amp;amp; \\vert \\\\ b_1 &amp;amp; b_2 &amp;amp; N \\\\ \\vert &amp;amp; \\vert &amp;amp; \\vert\\end{pmatrix}.\\]Since \\(b&#39;\\) is an orthonormal set, it follows that \\(M_{b&#39; \\to e} \\in O(3)\\), so \\(M_{e \\to b&#39;} = (M_{b&#39; \\to e})^{-1} = (M_{b&#39; \\to e})^\\top\\). It follows that the matrix for \\(\\pi\\) w.r.t. the bases \\(e,e&#39;\\) of \\(\\mathbb R^3,\\mathbb R^2\\) respectively is\\[\\pi_{e,e&#39;} = T_{b,e&#39;} \\pi&#39;_{b&#39;,b} M_{e \\to b&#39;} =\\begin{pmatrix} 1 &amp;amp; 0 \\\\ 0 &amp;amp; 1\\end{pmatrix}\\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0 \\\\ 0 &amp;amp; 1 &amp;amp; 0\\end{pmatrix}\\begin{pmatrix} \\text{---} &amp;amp; b_1 &amp;amp; \\text{---} \\\\ \\text{---} &amp;amp; b_2 &amp;amp; \\text{---} \\\\ \\text{---} &amp;amp; N &amp;amp; \\text{---}\\end{pmatrix} =\\begin{pmatrix} \\text{---} &amp;amp; b_1 &amp;amp; \\text{---} \\\\ \\text{---} &amp;amp; b_2 &amp;amp; \\text{---}\\end{pmatrix} =: M.\\]Now, recall that there is a pair \\((\\theta,\\phi)\\) corresponding to \\(N = \\tau(\\theta,\\phi)\\). For simplicity, we will assume that \\(\\theta \\in (-\\pi/2,\\pi/2)\\), so that a suitable restriction of \\(\\tau\\) forms a regular chart for \\(S^2\\). We aim to find an orthonormal basis for \\(\\Pi\\) by finding an orthonormal basis for \\(T_NS^2\\). Note that \\(\\{\\tau_u,\\tau_v\\}\\) forms a basis for \\(T_NS^2\\), where\\[\\tau_u(\\theta,\\phi) = (-\\sin\\theta\\cos\\phi,-\\sin\\theta\\sin\\phi,\\cos\\theta)\\]and\\[\\tau_v(\\theta,\\phi) = (-\\cos\\theta\\sin\\phi,\\cos\\theta\\cos\\phi,0).\\]It is easy to check that these are orthogonal, so an orthonormal basis \\(\\{b_1,b_2\\}\\) for \\(\\Pi\\) is found by normalising these vectors, yielding\\[b_2 = (-\\sin\\theta\\cos\\phi,-\\sin\\theta\\sin\\phi,\\cos\\theta)\\]and\\[b_1 = (-\\sin\\phi,\\cos\\phi,0).\\](It turns out that this also works when \\(\\theta \\in \\{\\pm\\pi/2\\}\\); these span the tangent planes \\(T_{(0,0,\\pm 1)}S^2 = \\mathbb R^2 \\times \\{0\\}\\)!) Note that we needed to take \\(b_1 = \\tau_v/\\lVert \\tau_v\\rVert\\) and \\(b_2 = \\tau_u/\\lVert \\tau_u\\rVert\\), so that indeed \\(b_1 \\times b_2 = N = \\tau(\\theta,\\phi)\\).In summary, for our perspective given by spherical coordinates \\((\\theta,\\phi)\\) (or equivalently \\(N = \\tau(\\theta,\\phi) \\in S^2\\)), the projection \\(\\pi : \\mathbb R^3 \\to \\mathbb R^2\\) is given by\\[\\begin{equation*} \\pi(x,y,z) = \\underbrace{ \\begin{pmatrix} -\\sin\\phi &amp;amp; \\cos\\phi &amp;amp; 0 \\\\ -\\sin\\theta\\cos\\phi &amp;amp; -\\sin\\theta\\sin\\phi &amp;amp; \\cos\\theta \\end{pmatrix}}_{M = M(\\theta,\\phi)} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\begin{pmatrix} -x\\sin\\phi + y\\cos\\phi \\\\ -x\\sin\\theta\\cos\\phi - y\\sin\\theta\\sin\\phi + z\\cos\\theta \\end{pmatrix}. \\tag{*}\\end{equation*}\\]Visualising the surface in DesmosIf we wish to plot \\(S\\) as the graph of \\(f\\), take \\(\\sigma(u,v) = (u,v,f(u,v))\\). Then it reduces to the problem of plotting the image of \\(\\sigma\\), or at least its projection under \\(\\pi\\). It would be useless (given limitations on Desmos) to present a filled-in outline—we would get a single splotch of colour (with jagged edges)! Instead, we use the idea that the domain \\(U\\) is an open subset of \\(\\mathbb R^2,\\)\\footnote{Desmos does not like strict inequalities, so they are often closed subsets instead, but we can ignore the boundary of \\(U\\).} and for fixed \\((u,v) \\in U\\), we consider the curves \\(x_u,y_v : I_u,J_v \\to U\\) in \\(U\\) (for suitable open intervals \\(I_u,J_v\\)), where \\(x_u(t) = (u,t)\\) and \\(y_v(t) = (t,v)\\), i.e. we fix the \\(u\\) or \\(v\\) coordinate, and let the other vary.Consider a set of points \\(\\{(u_i,v_i)\\}_i \\subseteq U\\), and the families of curves \\(\\{x_{u_i}\\}_i,\\{y_{v_i}\\}_i\\) so-defined. Then for each of the curves (generically called \\(\\alpha : I \\to U\\)), we plot the image of \\(\\gamma = \\sigma \\circ \\alpha : I \\to S\\), a curve in \\(S\\), under the projection \\(\\pi\\), yielding two families \\(\\{\\pi \\circ \\sigma \\circ x_{u_i}\\}_i\\) (fixing \\((x =)\\, u = u_i\\), plotted in red) and \\(\\{\\pi \\circ \\sigma \\circ y_{v_i}\\}_i\\) (fixing \\((y =)\\, v = v_i\\), plotted in blue) of curves in \\(\\mathbb R^2\\), representing moving along \\(S\\) using \\(\\sigma\\), with one input fixed. In the visualisation, we assume that \\(U = (a_1,a_2) \\times (b_1,b_2)\\) is a box,\\footnote{Technically \\(U = [a_1,a_2] \\times [b_1,b_2]\\), so we have a surface with boundary… but we can ignore this, as mentioned earlier.} and take \\(n_1,n_2\\) curves of constant separation in \\(U\\) in each direction. This creates the desired projection of the “wire-frame” on \\(S\\), and varying \\((\\theta,\\phi)\\) allows us to visualise the plot of \\(S\\) from all angles, giving it a 3-dimensional effect.Differential geometry of the projection: changing perspectiveFor spherical coordinates \\((\\theta,\\phi)\\), let principal latitude denote \\(\\theta_0 \\in [-\\pi/2,\\pi/2]\\) such that there is \\(\\phi_0 \\in \\mathbb R\\) with \\(\\tau(\\theta,\\phi) = \\tau(\\theta_0,\\phi_0)\\). We see that \\(M(\\theta,\\phi)\\) is a smooth function of \\(\\theta,\\phi\\), so the matrix (and projection) smoothly varies with \\(\\theta,\\phi\\):\\[M_\\theta(\\theta,\\phi) =\\begin{pmatrix} 0 &amp;amp; 0 &amp;amp; 0 \\\\ -\\cos\\theta\\cos\\phi &amp;amp; -\\cos\\theta\\sin\\phi &amp;amp; -\\sin\\theta\\end{pmatrix}\\]and\\[\\begin{equation*} M_\\phi(\\theta,\\phi) = \\begin{pmatrix} -\\cos\\phi &amp;amp; -\\sin\\phi &amp;amp; 0 \\\\ \\sin\\theta\\sin\\phi &amp;amp; -\\sin\\theta\\cos\\phi &amp;amp; 0 \\end{pmatrix} \\tag*{(from (*)).}\\end{equation*}\\]Fixing a point \\(p = (x,y,z) \\in \\mathbb R^3\\), we can think of \\(\\pi\\) as a function \\(\\mathbb R^2 \\to \\mathbb R^2\\), where the inputs are spherical coordinates \\((\\theta,\\phi)\\); let us call this map \\(\\pi&#39; : \\mathbb R^2 \\to \\mathbb R^2\\), \\((\\theta,\\phi) \\mapsto \\pi(p) = M(\\theta,\\phi)p\\). Then the directional derivatives of \\(\\pi&#39;\\) are given by \\(D_{(\\theta,\\phi)}\\pi&#39; : T_{(\\theta,\\phi)}\\mathbb R^2 \\to T_{\\pi&#39;(\\theta,\\phi)}\\mathbb R^2\\), which is such that\\[(\\lambda,\\mu) \\mapsto \\underbrace{\\begin{pmatrix} \\vert &amp;amp; \\vert \\\\ \\pi&#39;_\\theta &amp;amp; \\pi&#39;_\\phi \\\\ \\vert &amp;amp; \\vert\\end{pmatrix}}_{D\\pi&#39;(\\theta,\\phi)}\\begin{pmatrix} \\lambda \\\\ \\mu\\end{pmatrix} =\\begin{pmatrix} 0 &amp;amp; -x\\cos\\phi - y\\sin\\phi \\\\ -x\\cos\\theta\\cos\\phi - y\\cos\\theta\\sin\\phi - z\\sin\\theta &amp;amp; x\\sin\\theta\\sin\\phi - y\\sin\\theta\\cos\\phi\\end{pmatrix}\\begin{pmatrix} \\lambda \\\\ \\mu\\end{pmatrix}.\\]So, if we change perspective from \\((\\theta,\\phi)\\) with velocity \\((\\lambda,\\mu) \\in T_{(\\theta,\\phi)}\\mathbb R^2\\) (i.e. increasing latitude by \\(\\lambda\\) and longitude by \\(\\mu\\)), the image of \\(p\\) in \\(\\mathbb R^2\\) moves with velocity \\(D_{(\\theta,\\phi)}\\pi&#39;(\\lambda,\\mu)\\), given explicitly above. Note that\\[D_{(\\theta,\\phi)}\\pi&#39;(\\lambda,\\mu) = \\lambda M_\\theta(\\theta,\\phi)p + \\mu M_\\phi(\\theta,\\phi)p;\\]this relates the directional derivatives of \\(\\pi&#39;\\) to the partial derivatives of \\(M\\).Let us consider what happens to \\(\\pi(p)\\) when we fix longitude \\(\\phi\\) and vary latitude \\(\\theta\\). Taking \\(\\lambda = 1\\) and \\(\\mu = 0\\) reveals a directional derivative of\\[M_\\theta(\\theta,\\phi)p = (0,-x\\cos\\theta\\cos\\phi - y\\cos\\theta\\sin\\phi - z\\sin\\theta)\\]in the \\((1,0)\\) direction. In particular, the \\(x\\)-coordinate of \\(\\pi(p)\\) does not change when only \\(\\theta\\) is changed, which makes sense since we view this as tilting the plane \\(\\Pi\\) up or down. However, the \\(y\\)-coordinate changes at a rate precisely equal to \\(-\\tau(\\theta,\\phi) \\cdot p = -N \\cdot p = \\tau(-\\theta,\\phi + \\pi) \\cdot p\\) (since \\(\\tau\\) gives points on \\(S^2\\)). For nonzero \\(p\\), this is zero precisely when \\(p\\), or equivalently \\(p/\\lVert p\\rVert \\in S^2\\), is orthogonal to \\(N \\in S^2\\), the unit normal vector to the plane of projection \\(\\Pi\\). This holds when \\(N \\in T_{p/\\lVert p\\rVert}S^2\\); if \\(\\tau(\\mathbb R \\times \\{\\phi\\}) \\subseteq T_{p/\\lVert p\\rVert}S^2\\), then this occurs for every latitude \\(\\theta\\), but otherwise, \\(\\tau(\\mathbb R \\times \\{\\phi\\})\\) is a circle on \\(S^2\\) and intersects \\(T_{p/\\lVert p\\rVert}S^2\\) for precisely one latitude \\(\\theta\\) (modulo \\(\\pi\\)). From this, we conclude that for principal latitudes \\(\\theta\\), if \\(p/\\lVert p\\rVert = \\pm(N \\times \\tau(\\theta + \\pi/4,\\phi))\\), \\(\\pi(p)\\) is always fixed when varying latitude \\(\\theta\\) (the directional derivative is zero); otherwise, there is precisely one latitude \\(\\theta\\) (or two, whence \\(\\theta = \\pm\\pi/2\\)) for which \\(\\pi(p)\\) has velocity zero.The above observations agree with a direct calculation: the curve in \\(\\mathbb R^2\\) that \\(\\pi(p)\\) traces for fixed longitude \\(\\phi\\) is\\[\\beta_p : \\mathbb R \\to \\mathbb R^2, \\quad \\beta_p(t) = (\\underbrace{-x\\sin\\phi + y\\cos\\phi}_{\\text{constant}},\\underbrace{-x\\sin t\\cos\\phi - y\\sin t\\sin\\phi + z\\cos t}_{\\text{trigonometric with period}\\ 2\\pi}).\\]Now, let us consider what happens to \\(\\pi(p)\\) when we fix latitude \\(\\theta\\) and vary longitude \\(\\phi\\). Taking \\(\\lambda = 0\\) and \\(\\mu = 1\\) gives a directional derivative of\\[M_\\phi(\\theta,\\phi)p = (-x\\cos\\phi - y\\sin\\phi,x\\sin\\theta\\sin\\phi - y\\sin\\theta\\cos\\phi)\\]in the \\((0,1)\\) direction. A direct calculation gives that the curve in \\(\\mathbb R^2\\) that \\(\\pi(p)\\) traces for fixed latitude \\(\\theta\\) is\\[\\delta_p : \\mathbb R \\to \\mathbb R^2, \\quad \\delta_p(t) = (-x\\sin t + y\\cos t,-x\\sin\\theta\\cos t - y\\sin\\theta\\sin t + z\\cos\\theta);\\]the above directional derivative is simply \\(\\dot\\delta_p(\\phi)\\). By trigonometry, we know that letting \\(T = t + \\cos^{-1}(y/\\sqrt{x^2 + y^2})\\),\\[\\delta_p(t) = (\\sqrt{x^2 + y^2}\\cos T,-\\sin\\theta\\sqrt{x^2 + y^2}\\sin T + z\\cos\\theta);\\]this is clearly an ellipse (with period \\(2\\pi\\)) with axis lengths \\(\\sqrt{x^2 + y^2}\\) and \\(\\lvert\\sin\\theta\\rvert\\sqrt{x^2 + y^2}\\), oriented negatively (clockwise) whenever principal latitude is positive (and positively if principal latitude is negative). Additionally, it has 4 vertices by Example 6.3 of chapter 4 (as long as \\(\\lvert\\sin\\theta\\rvert \\neq 1\\) and both axis lengths are nonzero); these vertices correspond to locations where the \\(x\\) or \\(y\\)-coordinate of \\(\\pi(p)\\) is greatest or smallest. In summary, we see that for fixed latitude \\(\\theta\\), projected points move in an elliptic shape (in a clockwise direction when viewed from with positive principal latitude); this agrees with the intuition that as we increase longitude \\(\\phi\\), in order for the normal \\(N\\) to the plane of projection \\(\\Pi\\) to point “into the screen”, points must rotate clockwise about the projected \\(z\\)-axis.This concludes our analysis of the 2-dimensional visualisation of surfaces in \\(\\mathbb R^3\\) on Desmos. We saw some commentary on the derivation of the projection, using some linear algebra. Then we proceeded to analyse how curves are represented in the plot, as a “wire-frame”, and finally, we analysed the effect of changing latitude and longitude on the positions of points in the plot, rounding off a treatment of the algebraic, analytic, and geometric properties of the visualisation.AcknowledgementsI would like to acknowledge Dan Mathews for giving useful feedback (especially with respect to interpreting the effect on changing perspective on the position of points) and verifying the procedure used to derive the projection matrix. Errors in my initial formula for the projection were also corrected through discussion and testing with various members of the Maths @ Monash Discord server. To switch modes, click on the “plot” folder to hide it, and click on the “parametric plot” folder to show that. &amp;#8617; See Example 2.17 from MTH3110 chapter 5 notes. &amp;#8617; " }, { "title": "Why probability and statistics need measure theory, part 2", "url": "/posts/measure-theory-in-probability-2/", "categories": "Epic Maths Time, New Perspectives", "tags": "probability, measure-theory, statistics, topology, uni-maths", "date": "2021-06-18 13:14:00 +1000", "snippet": "If you haven’t already read part 1, make sure you read it here first! Or else, much of the below will not make sense!Random variables: neither random, nor a variableWhat is a random variable?Let \\((\\Omega,\\mathcal F,\\mathbb P)\\) be a probability space.Definition 10. A random variable is a measurable function \\(X : \\Omega \\to E\\), where \\((E,\\mathcal E)\\) is the state space. We usually take \\(E\\) to be a topological space \\((E,\\mathcal T)\\) (e.g. \\(\\mathbb R,\\mathbb R^n,\\mathbb C\\) with the usual topologies), so that \\((E,\\mathcal B)\\) is endowed with the Borel sigma algebra.Clearly we must define measurable functions.Definition 11. A function \\(f : (\\Omega,\\mathcal F) \\to (E,\\mathcal E)\\) between measurable spaces is measurable if, for any measurable subset \\(A \\in \\mathcal E\\) of \\(E\\), its preimage\\[f^{-1}(A) := \\{x \\in \\Omega : f(x) \\in A\\}\\]is measurable in \\(\\Omega\\), i.e. \\(f^{-1}(A) \\in \\mathcal F\\). If \\((E,\\mathcal T)\\) is a topological space and \\(\\mathcal E = \\mathcal B(\\mathcal T)\\), then \\(f\\) is Borel measurable.For now, we will take \\(\\Omega = E = \\mathbb R\\), and the Borel sigma algebra on \\(\\mathbb R\\). What are some examples of measurable functions? Well, it turns out that every function you can think of (well, with probability 1) will be measurable! One particularly nice class of measurable functions in this case are the continuous functions:Definition 12. A function \\(f : (\\Omega,\\tau) \\to (E,\\mathcal T)\\) between topological spaces is continuous if, for any open subset \\(A \\in \\mathcal T\\) of \\(E\\), its preimage \\(f^{-1}(A)\\) is open in \\(\\Omega\\), i.e. \\(f^{-1}(A) \\in \\tau\\).Hopefully you can see the similarity: just replace “measurable” with “open”! Again, this may be different to the usual notion of continuity that you know (nearby inputs map to nearby outputs), but they turn out to be equivalent. Here is a quick proof of the above claim:Proposition 13. Suppose \\(f : (\\Omega,\\tau) \\to (E,\\mathcal T)\\) is a continuous function. Then for a sigma algebra \\(\\mathcal F\\) on \\(\\Omega\\) that contains the Borel sigma algebra \\(\\mathcal B(\\tau)\\), the function \\(f : (\\Omega,\\mathcal F) \\to (E,\\mathcal B(\\mathcal T))\\) is measurable.Proof. Let \\(A \\in \\mathcal B(\\mathcal T)\\) be a Borel set. Recall that this means that there is a countable sequence of union/intersection/complement operations such that \\(A\\) is constructed from a (countable) family of open sets \\((A_i)_{i \\in I}\\). But note that the preimage of any union/intersection/complement is the union/intersection/complement of the preimages (in general, \\(f^{-1}(A \\cup B) = f^{-1}(A) \\cup f^{-1}(B)\\), \\(f^{-1}(A \\cap B) = f^{-1}(A) \\cap f^{-1}(B)\\), and \\(f^{-1}(A \\setminus B) = f^{-1}(A) \\setminus f^{-1}(B)\\)), so it follows that \\(f^{-1}(A)\\) is constructed from the sets \\((f^{-1}(A_i))_{i \\in I}\\) using the exact same sequence of operations. But \\(f^{-1}(A_i)\\) is open for any \\(i\\) by continuity of \\(f\\) (by definition), thus measurable (since \\(\\mathcal F\\) contains \\(\\mathcal B(\\tau)\\), which contains all open sets in \\(\\Omega\\)). So \\(f^{-1}(A)\\) is constructed from the measurable sets \\((f^{-1}(A_i))_{i \\in I}\\) using a countable sequence of union/intersection/complement operations, so \\(f^{-1}(A) \\in \\mathcal F\\) (sigma algebras are closed under these operations). \\(\\square\\)This immediately gives many, many measurable functions! Assuming the sample space is \\(\\mathbb R\\), polynomial functions, rational functions, exponentials, trigonometric functions, logarithmic functions etc. are all measurable, and so are their sums, products, quotients (where defined), and compositions (which are all continuous)! So are the minimum/maximum of two continuous/measurable functions (in fact, supremums and infimums also work). So is the wild Weierstrass function, which is differentiable nowhere, but continuous everywhere, thus measurable!But it turns out that many discontinuous functions are also measurable. Let’s look at one example: the signum function\\[\\operatorname{sgn} : \\mathbb R \\to \\mathbb R, \\quad x \\mapsto \\begin{cases} 1, &amp;amp; x &amp;gt; 0 \\\\ 0, &amp;amp; x = 0 \\\\ -1, &amp;amp; x &amp;lt; 0 \\end{cases}\\](a friend-favourite, for some reason…). To show this, we need to show that for any Borel set \\(A \\subseteq \\mathbb R\\), its preimage \\(\\operatorname{sgn}^{-1}(A) = \\{x \\in \\mathbb R : \\operatorname{sgn}(x) \\in A\\}\\) is again a Borel set in \\(\\mathbb R\\). One approach considers 8 cases; we do only one. Suppose that \\(0,1 \\in A\\) but \\(-1 \\not\\in A\\). Then\\[\\operatorname{sgn}^{-1}(A) = \\{x \\in \\mathbb R : \\operatorname{sgn}(x) \\in A\\} = \\{x \\in \\mathbb R : \\operatorname{sgn}(x) \\in \\{0,1\\}\\}\\]since \\(\\operatorname{sgn}\\) only takes on values in \\(\\{0,\\pm 1\\}\\). Therefore, \\(\\operatorname{sgn}^{-1}(A) = [0,\\infty)\\); this is a Borel set since its complement is the open set \\((-\\infty,0)\\) (and open sets are always Borel sets).Challenge question 5. Complete the above proof that the signum function is measurable by identifying the remaining 7 cases, and checking that \\(\\operatorname{sgn}^{-1}(A)\\) is a Borel set in each case.Going back to our example 9 with the uniform distribution on \\([0,1]\\), it now follows that the inclusion map \\(X : \\Omega \\hookrightarrow \\mathbb R, x \\mapsto x\\), is a random variable, since it is continuous (thus measurable). This is how we typically think of a random variable with a uniform distribution!Briefly, let’s consider random variables from finite probability spaces. Since the natural sigma algebra is the power set (the discrete topology), it follows that every function is measurable. So any function \\(X : \\Omega \\to E\\) is a valid random variable. Let’s now look at random variables in a bit more depth.Fun with random variablesLet’s first introduce some notation. Recall that a random variable \\(X : \\Omega \\to E\\) is a measurable function from a probability space \\((\\Omega,\\mathcal F,\\mathbb P)\\) to a measurable space \\((E,\\mathcal E)\\). It’s not a variable! And it’s not even random… the “randomness” comes from the fact that a probability measure assigns “chances” to different events. Let’s now combine the notion of random variable, with the notion of probability space. This is how you’ve learnt random variables in high school/early university!For the following, we take \\(E = \\mathbb R\\). Let \\(A \\subseteq \\mathbb R\\) be a Borel set. Then since \\(X\\) is measurable, \\(X^{-1}(A)\\) is a valid event. Thus we may take its probability, and we write it in the following ways:\\[\\mathbb P(X^{-1}(A)) = \\mathbb P(\\{\\omega \\in \\Omega : X(\\omega) \\in A\\}) = \\mathbb P(X \\in A).\\]Of these, the last is probably the most familiar. But they all mean the same thing! In fact, what we mean when we write \\(X \\in A\\), is precisely the event \\(X^{-1}(A)\\)!Example 8 (continued from part 1). Recall this example, in which we had an infinite sequence of coin tosses and a sample space \\(\\Omega = \\{0,1\\}^\\infty\\). For \\(n \\geq 1\\), consider the following random variable \\(X_n : \\Omega \\to \\mathbb R,\\)\\[\\omega = (\\omega_1,\\omega_2,...) \\mapsto \\omega_n,\\]which is simply projection onto the \\(n\\)th coordinate. For example, if \\(n = 2\\) and we consider the outcome \\(\\omega = (1,0,1,0,...)\\), we get \\(X_2(\\omega) = 0\\). We can see that this essentially measures the outcome of the \\(n\\)th toss: if it was a tail, then \\(X_n(\\omega) = 0\\); if a head, then \\(X_n(\\omega) = 1\\). Assuming that each toss independently has probability \\(p \\in (0,1)\\) of appearing as a head, we observe the following: for any \\(n\\),\\[\\mathbb P(X_n = 1) = \\mathbb P(X_n^{-1}(\\{1\\})) = \\mathbb P(\\{\\omega \\in \\Omega : X_n(\\omega) = 1\\}) = p,\\]by our assertion. Similarly, \\(\\mathbb P(X_n = 0) = \\mathbb P(\\{\\omega \\in \\Omega : X_n(\\omega) = 0\\}) = 1 - p\\), since\\[X_n^{-1}(0) \\cup X_n^{-1}(1) = X_n^{-1}(\\{0,1\\}) = \\Omega\\]and\\[X_n^{-1}(0) \\cap X_n^{-1}(1) = X_n^{-1}(\\{0\\} \\cap \\{1\\}) = X_n^{-1}(\\varnothing) = \\varnothing,\\]i.e. the two events \\(\\{X_n = 0\\}\\) and \\(\\{X_n = 1\\}\\) are disjoint (as expected), and their union is the sample space (this is called a partition), so the sum of the above two probabilities should be 1. (Note that here we use general properties of preimages of functions (\\(f^{-1}(A \\cup B) = f^{-1}(A) \\cup f^{-1}(B)\\), \\(f^{-1}(A \\cap B) = f^{-1}(A) \\cap f^{-1}(B)\\), and \\(f^{-1}(A \\setminus B) = f^{-1}(A) \\setminus f^{-1}(B)\\)), and when taking the preimage of a point, we often drop the curly brackets. It does not mean the inverse function; \\(X_n\\) is certainly not invertible!)Example 9 (continued from part 1). Let’s again consider the uniform distribution on \\([0,1]\\), and the random variable \\(X : \\Omega \\hookrightarrow \\mathbb R, x \\mapsto x\\) defined above. Then, for example, for \\((a,b) \\subseteq (0,1)\\),\\[\\mathbb P(a &amp;lt; X &amp;lt; b) = \\mathbb P(X^{-1}((a,b))) = \\mathbb P((a,b)) = b - a.\\]Now, recall that the composition of measurable functions is measurable, so if \\(f\\) is for instance continuous, then \\(f(X) = f \\circ X\\) is also a random variable! Let’s take \\(f\\) to be the squaring function \\(x \\mapsto x^2\\). Let’s investigate the random variable \\(f(X) = X^2 : [0,1] \\to \\mathbb R\\) where \\(X^2(\\omega) = \\omega^2\\):Challenge question 5 (related to example 9). Find \\((X^2)^{-1}(I) \\subseteq [0,1]\\) for any open interval \\(I = (a,b) \\subseteq [0,1]\\). Is this a valid event (a Borel set in \\([0,1]\\))? Thus compute the probability \\(\\mathbb P(a &amp;lt; X^2 &amp;lt; b)\\). For \\(x \\in (0,1)\\), find \\((X^2)^{-1}((-\\infty,x])\\) and thus find \\(G(x) = \\mathbb P(X^2 \\leq x)\\). What is \\(G(b) - G(a)\\)? Can you find a function \\(g : (0,1) \\to \\mathbb R\\) such that \\(\\mathbb P(a &amp;lt; X^2 &amp;lt; b) = \\int_a^b g(x)\\,dx\\)? (Hint: consider the function \\(G : (0,1) \\to [0,1]\\), and apply the fundamental theorem of calculus, which implies \\(\\int_a^b G&#39;(x)\\,dx = G(b) - G(a)\\).) This is (almost) the probability density function (or pdf) of \\(X^2\\).Post your solutions in the unofficial Maths @ Monash Discord!Distributions: a change in perspectiveProbability distributions and pushforwardsA subtle but important change of perspective is to notice that for a probability measure \\(\\mathbb P\\) on the sample space, and a random variable \\(X : \\Omega \\to E\\), we can actually define a new probability measure on the state space \\(E\\), that arises naturally from \\(X\\)! This is the pushforward measure \\(\\mathbb P_X = X_*\\mathbb P = \\mathbb P \\circ X^{-1} : \\mathcal E \\to [0,1]\\), defined by\\[\\mathbb P_X(A) := \\mathbb P(X^{-1}(A)) = \\mathbb P(X \\in A).\\]Here, \\(A \\in \\mathcal E\\) is a (Borel) measurable set. Then the triple \\((E,\\mathcal E,\\mathbb P_X)\\) is a probability space, induced by the random variable \\(X\\), so we can directly talk about probabilities using only the state space! And this is crucial in defining probability distributions, as we can then largely ignore the sample space!This is something that we like to do a lot in maths: which is to start off with a structure on a set, and use a mapping to transfer that structure over to a different set. This is one such example; other examples of similar structure-preserving maps are continuous maps (preserving open sets), homeomorphisms (preserving topologies), isometries (preserving distances), linear transformations (preserving vector space structure), homomorphisms/isomorphisms (preserving algebraic structure), and pullbacks of bilinear forms under a linear map.Now, let’s consider \\((-\\infty,x]\\) which is clearly a Borel set. We define the cumulative distribution function using the probability that \\(X\\) takes on a value in this set:Definition 14. For a random variable \\(X : \\Omega \\to \\mathbb R\\), its (cumulative) distribution function (cdf) is the measurable function \\(F_X : \\mathbb R \\to [0,1]\\), defined by\\[F_X(x) = \\mathbb P(X \\leq x) = \\mathbb P(X^{-1}((-\\infty,x])) = \\mathbb P_X((-\\infty,x]).\\]That is, the cdf of \\(X\\) gives us the probability measure of the event \\((-\\infty,x]\\), where we push the probability measure from the sample space over to the state space! Similarly, if we have a probability space \\((\\Omega,\\mathcal F,\\mathbb P)\\) with sample space \\(\\Omega \\subseteq \\mathbb R\\), we can define the distribution function of the probability measure \\(\\mathbb P\\) as \\(F : \\mathbb R \\to [0,1]， x \\mapsto \\mathbb P((-\\infty,x])\\).As a quick note, the cdf of a random variable \\(X\\) fully determines its properties, as we may recover the event \\(X^{-1}(A) = \\{X \\in A\\}\\) (thus \\(\\mathbb P(X \\in A)\\)) for any Borel set \\(A\\) from countable unions/intersections/complements of events \\(X^{-1}((-\\infty,x]) = \\{X \\leq x\\}\\) with \\(x \\in \\mathbb R\\).It is possible to see that any cdf must be increasing (i.e. if \\(a &amp;lt; b\\), then \\(F(a) \\leq F(b)\\)):Proof For \\(a &amp;lt; b\\), we have\\[F(b) = \\mathbb P((-\\infty,b]) = \\mathbb P((-\\infty,a] \\cup (a,b]) = \\mathbb P((-\\infty,a]) + \\underbrace{\\mathbb P((a,b])}_{\\geq 0} \\geq F(a). \\square\\]Additionally, cdfs have countably many discontinuities, and must be right-continuous, meaning that not every increasing measurable function with codomain \\([0,1]\\) is the cdf of some random variable.This change of perspective is useful, as it allows us to define when two random variables have the same probability distribution, even when they aren’t defined on the same probability space! We say that two random variables \\(X : (\\Omega_1,\\mathcal F_1,\\mathbb P_1) \\to (\\mathbb R,\\mathcal B)\\) and \\(Y : (\\Omega_2,\\mathcal F_2,\\mathbb P_2) \\to (\\mathbb R,\\mathcal B)\\) are equal in distribution if their cdfs are equal as functions: \\(F_X = F_Y\\); this means that \\(\\mathbb P_1(X \\leq x) = \\mathbb P_2(Y \\leq x)\\) for all \\(x \\in \\mathbb R\\) (note the different probability measures), or equivalently,\\[\\mathbb P_X((-\\infty,x]) = \\mathbb P_Y((-\\infty,x]),\\]which turns out to imply that \\(\\mathbb P_X = \\mathbb P_Y\\) (the pushforward measures) as probability measures on the state space \\((\\mathbb R,\\mathcal B)\\) (again via the Hahn-Kolmogorov theorem). And hopefully this explains why the pushforward measure is so important: \\(X\\) and \\(Y\\) have the same probability distribution if and only if they induce identical probability spaces on the event space (via the pushforward measure), even if they are defined on totally different sample spaces.Furthermore, this change in perspective allows us to “discard” the sample space, and instead consider a probability measure on the state space \\(\\mathbb R\\), in the sense that if \\((\\Omega,\\mathcal F,\\mathbb P)\\) is a probability space and \\(X : \\Omega \\to \\mathbb R\\) is a random variable with pushforward measure \\(\\mathbb P_X\\), we ignore this and work only with the probability space \\((\\mathbb R,\\mathcal B,\\mathbb P_X)\\), and we consider the properties of this probability space (expectation, density, etc.). This is the usual approach to learning random variables in early studies – do you ever remember thinking about the sample space when working with random variables? Most likely not.Examples of distributionsExample 15. Lets see an example of this, coming from our previous examples. Consider the first probability space to be the example with rolling two fair dice (independently) with \\(\\Omega_1 = \\{1,...,6\\} \\times \\{1,...,6\\}\\), and the second probability space be the uniform distribution on \\(\\Omega_2 = [0,1]\\). Clearly these random variables are vastly different. Define the random variable \\(X : \\Omega_1 \\to \\mathbb R\\) as giving \\(1\\) if the first die resulted in an equal or higher roll than the second, or \\(0\\) otherwise:\\[X(\\omega) = X((\\omega_1,\\omega_2)) = \\begin{cases} 1, &amp;amp; \\omega_1 \\geq \\omega_2 \\\\ 0, &amp;amp; \\omega_1 &amp;lt; \\omega_2 \\end{cases}\\]Let \\(Y : \\Omega_2 \\to \\mathbb R\\) be given by the following transformation:\\[Y(\\omega) = \\begin{cases} 1, &amp;amp; \\omega \\leq 21/36 \\\\ 0, &amp;amp; \\omega &amp;gt; 21/36 \\end{cases}\\]Let’s compute the cdfs of \\(X\\) and \\(Y\\). For \\(X\\), for any \\(x \\in (-\\infty,0)\\), we have \\(X^{-1}((-\\infty,x]) = \\varnothing\\), so \\(F_X(x) = \\mathbb P_X((-\\infty,x]) = \\mathbb P_1(\\varnothing) = 0\\). For \\(x \\in [0,1)\\), \\(X^{-1}((-\\infty,x]) = X^{-1}(0) = \\{(\\omega_1,\\omega_2) \\in \\Omega_1 : \\omega_1 \\geq \\omega_2\\}\\), so\\[F_X(x) = \\mathbb P_X((-\\infty,x]) = \\mathbb P_1(\\{(\\omega_1,\\omega_2) \\in \\Omega_1 : \\omega_1 \\geq \\omega_2\\}) = \\frac{21}{36}\\]by a simple combinatorial argument, and the fact that the 21 outcomes in that event are equiprobable. Now for \\(x \\in [1,\\infty)\\), \\(X^{-1}((-\\infty,x]) = X^{-1}(\\{0,1\\}) = \\Omega_1\\), so \\(F_X(x) = \\mathbb P_X((-\\infty,x]) = \\mathbb P_1(\\Omega_1) = 1\\). In summary:\\[F_X(x) = \\begin{cases} 0, &amp;amp; x &amp;lt; 0 \\\\ 21/36, &amp;amp; 0 \\leq x &amp;lt; 1 \\\\ 1, &amp;amp; x \\geq 1 \\end{cases}\\]Challenge question 6 (related to example 15). Compute the cdf of \\(Y\\), and show that \\(X\\) and \\(Y\\) are equal in distribution. (This then implies \\(\\mathbb P_X = \\mathbb P_Y\\) and \\(\\mathbb P_1(X \\in A) = \\mathbb P_2(Y \\in A)\\) for any Borel set \\(A\\), and we may as well forget about the original sample spaces and consider the abstract properties of their common induced probability space on \\(\\mathbb R\\)!) If you need a reminder of how \\((\\Omega_2,\\mathcal F_2,\\mathbb P_2)\\) works, the example is Example 9 in here.At this point, we are finally ready to define discrete and continuous random variables, or more fundamentally, probability distributions.Definition 16. A continuous random variable \\(X : \\Omega \\to \\mathbb R\\) is such that \\(\\mathbb P(X = x) = \\mathbb P_X(\\{x\\}) = 0\\) for all \\(x \\in \\mathbb R\\). An absolutely continuous random variable \\(X : \\Omega \\to \\mathbb R\\) is such that there exists a function \\(f : \\mathbb R \\to [0,\\infty]\\) such that \\(\\mathbb P(X \\in A) = \\int_A f(x)\\,dx\\) for any Borel set \\(A \\subseteq \\mathbb R\\). This function \\(f\\) is the probability density function (density/pdf) of \\(X\\). (Absolutely continuous random variables are continuous.) A discrete random variable \\(X : \\Omega \\to \\mathbb R\\) is such that there exists a countable Borel set \\(A\\) with \\(\\mathbb P(X \\in A) = \\mathbb P_X(A) = 1\\). (If \\(\\Omega\\) is discrete, any random variable will be discrete.)Note how densities are defined. We start with a probability space, with a probability measure \\(\\mathbb P\\) defined on it, and a random variable \\(X\\) mapping the sample space into the reals. A density is then a function that satisfies the particular property that\\[\\mathbb P(X \\in A) = \\mathbb P_X(A) = \\int_A f(x)\\,dx\\]for any Borel set \\(A \\subseteq \\mathbb R\\), which may feel backwards. Don’t we usually start with the density function? We can, and again this approach uses the idea that we can forget about the original sample space, and study the probability space via the pushforward measure. So when we gave the normal density\\[f_\\theta : \\mathbb{R} \\to \\mathbb{R}, \\quad x \\mapsto \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\\]at the start of part 1, we can either think of a probability space and a random variable which happens to have this as a density, or we can think of this density as characterising the pushforward measure of some random variable whose sample space is unimportant. And it is this second perspective that we tend to prefer, as the analysis (probability calculations, expectation/moments, statistics, etc.) then directly applies to any scenario in which the pushforward measure has the same density, even if the underlying experiment is different (as we saw in Example 15).Next up, to tackle the problem of unifying the concepts of densities and expectations of different types of distributions, we will consider a new form of integral: the Lebesgue integral. We leave this to the next part of this series!" }, { "title": "Why probability and statistics need measure theory, part 1", "url": "/posts/measure-theory-in-probability/", "categories": "Epic Maths Time, New Perspectives", "tags": "probability, measure-theory, statistics, topology, uni-maths", "date": "2021-06-16 21:57:00 +1000", "snippet": "Introduction to the problemYou may have encountered continuous probability distributions such as the normal distribution. It’s often used to model things in the real world, and has nice statistical properties. You know the bell curve. But what you may not have seen is its formula: the probability density function (often shortened to just density),\\[f_\\theta : \\mathbb{R} \\to \\mathbb{R}, \\quad x \\mapsto \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\\]given a value of \\(\\theta = (\\mu,\\sigma^2) \\in \\Theta\\). In our case, \\(\\Theta = \\mathbb{R} \\times (0,\\infty)\\); this is known as the parameter space, and this is central to the study of statistics.How does this relate to probability? Well, everything. We begin informally: suppose that \\(X\\) is a continuous random variable with density \\(f_\\theta\\). The meaning of this is unimportant initially; think of \\(X\\) as a “variable” that takes on values randomly (we will see that this is very much not a random variable should be). For a “reasonable” subset \\(A \\subseteq \\mathbb{R}\\), let \\(\\mathbb{P}(X \\in A)\\) denote the probability that \\(X \\in A\\), i.e. the probability of the event \\(\\{X \\in A\\}\\) (whatever that means). It turns out that, and as is often taught in a class in probability (even at high school level),\\[\\mathbb P(X \\in A) = \\int_A f_\\theta(x)\\,dx = \\int_A \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\\,dx.\\]In fact, we are kind of working backwards. The probability density function is essentially defined to be a function such that integrating it over the desired subset yields the probability of \\(X\\) taking on a value in that set. We get a couple of questions: How does the probability-assignment process work? What should \\(A\\) be allowed to be? Should we allow every subset of the reals? In particular, if \\(A = \\{x_0\\}\\) for some \\(x_0 \\in \\mathbb{R}\\), the previous formula implies that \\(\\mathbb P(X = x_0) = 0\\), as an integral over a point. Does that make sense? Does that mean the event \\(\\{X = x_0\\}\\) is impossible? (It turns out it is possible!) Also, what about the seemingly irreconcilable differences between continuous and discrete probability distributions (density vs mass, expectation formulas, the general vibe, etc.)?It turns out that measure theory has the answer to all of these questions.Some measure theory, with a probabilistic flavourTopologies and sigma algebrasMeasure theory is essentially the theory of assigning sizes to sets, done rigorously. We will motivate probability spaces, which are measure spaces in which the “total size” is 1. But first, we define a topology; it turns out that it is intimately related to measures. (Warning: this subsection is rather technical, so feel free to skim over it; it’s mostly here for background.)Definition 1. Let \\(\\Omega\\) be a set, called the sample space in our context. A topology on \\(\\Omega\\) is a collection \\(\\tau\\) of subsets of \\(\\Omega\\) satisfying the following properties: (Whole and empty set) The whole and empty sets are elements of the topology: \\(\\Omega \\in \\tau\\) and \\(\\varnothing \\in \\tau\\); (Closure under arbitrary unions) For an indexed collection of sets \\((A_i)_{i \\in I}\\) with each \\(A_i \\in \\tau\\) (finite or infinite), their union \\(\\bigcup_{i \\in I} A_i \\in \\tau\\) also; (Closure under finite intersections) For a finite collection of sets \\(A_1,A_2,...,A_n\\) with each \\(A_i \\in \\tau\\), their intersection \\(\\bigcap_{i = 1}^n A_i \\in \\tau\\) also.If \\(\\tau\\) is a topology on \\(\\Omega\\), then the pair \\((\\Omega,\\tau)\\) is a topological space, and the elements in the topology (subsets of \\(\\Omega\\)) are called open sets. A set \\(B\\) is closed if \\(\\Omega \\setminus B\\) is open.Yes, this is the topology in which donuts are the same as (homeomorphic to) coffee mugs!Let’s look at a simple example of a topological space: the usual one \\((\\mathbb{R},\\tau)\\) on the reals. We define it via the open sets: a subset \\(A \\subseteq \\mathbb{R}\\) is open if, for each point \\(a \\in A\\), there is an open interval \\(I = (a - \\epsilon,a + \\epsilon)\\) (with \\(\\epsilon &amp;gt; 0\\)) centred at \\(a\\) that is wholly contained in \\(A\\), i.e. \\(I \\subseteq A\\). For example, the set \\(\\mathbb{R}\\) is open: for \\(a \\in \\mathbb{R}\\), we have \\((a - 1,a + 1) \\subseteq \\mathbb{R}\\). Additionally, the set \\((0,1)\\) is open: for \\(a \\in (0,1)\\), let \\(\\epsilon = \\min(a,1 - a) \\leq a,1 - a\\); note that \\(0 = a - a \\leq a - \\epsilon\\) and \\(a + \\epsilon \\leq a + (1 - a) = 1\\), so \\((a - \\epsilon,a + \\epsilon) \\subseteq (0,1)\\). However, the set \\([0,1)\\) is not open: at \\(a = 0\\), every open interval centred at \\(0\\) goes “outside” of \\((0,1)\\). From these, we see that \\(\\mathbb R \\setminus \\mathbb R = \\varnothing\\) and \\(\\mathbb R \\setminus (0,1) = (-\\infty,0] \\cup [1,\\infty)\\) are closed. A similar argument shows that \\([0,1]\\) is closed (its complement is open); this suggests that the intervals that are open sets are precisely the open intervals \\((a,b)\\), and those that are closed sets are precisely the closed intervals \\([a,b]\\) (where we allow infinity and \\(a = b\\)).Now back to our question: which sets can we talk about probabilities of? Suppose that we only allowed open and closed sets. Then sets as simple as \\([0,1)\\) would be disallowed, but it seems quite reasonable to talk about the probability of \\(\\{0 \\leq X &amp;lt; 1\\}\\)! Thus we introduce sigma algebras:Definition 2. Let \\(\\Omega\\) be a set, called the sample space in our context. A sigma algebra (of sets) on \\(\\Omega\\) is a collection \\(\\mathcal F\\) of subsets of \\(\\Omega\\) satisfying the following properties: (Whole and empty set) The whole and empty sets are elements of the sigma algebra: \\(\\Omega \\in \\mathcal F\\) and \\(\\varnothing \\in \\mathcal F\\) (we may omit one of these); (Closure under countable unions) For a countable collection of sets \\((A_i)_{i = 1}^\\infty\\) with each \\(A_i \\in \\mathcal F\\), their union \\(\\bigcup_{i = 1}^\\infty A_i \\in \\mathcal F\\) also; (Closure under complements) If \\(A \\in \\mathcal F\\), then its complement \\(A^c := \\Omega \\setminus A \\in \\mathcal F\\).If \\(\\mathcal F\\) is a sigma algebra on \\(\\Omega\\), then the pair \\((\\Omega,\\mathcal F)\\) is a measurable space, and the elements in the sigma algebra (subsets of \\(\\Omega\\)) are called measurable sets; in the context of probability, we call them events.Note that by de Morgan’s laws, we also have closure under countable intersections: if \\(A_1,A_2,... \\in \\mathcal F\\), then \\(A_1^c,A_2^c,... \\in \\mathcal F\\); then \\(\\bigcup_{i = 1}^\\infty A_i^c = \\left(\\bigcap_{i = 1}^\\infty A_i\\right)^c \\in \\mathcal F\\), so its complement \\(\\bigcap_{i = 1}^\\infty A_i \\in \\mathcal F\\).Now, what’s an example of a sigma algebra on the reals? For this, essentially take our standard topology from above, and just force it to be a sigma algebra: this gives the Borel sigma algebra.Definition 3. Let \\((\\Omega,\\tau)\\) be a topological space. The Borel sigma algebra \\(\\mathcal B = \\mathcal B(\\tau)\\) is the (smallest) sigma algebra generated by \\(\\tau\\), formed from a countable number of unions, intersections, and complements of open sets in \\(\\Omega\\). Elements of \\(\\mathcal B\\) are then called Borel sets.For example, \\([0,1)\\) is a Borel set. Why? Notice that \\([0,1) = [(-\\infty,0) \\cup [1,\\infty)]^c\\). Since \\((-\\infty,0)\\) is open, it must be a Borel set (as the Borel sigma algebra contains the topology). Also, since \\((-\\infty,1)\\) is open, it too is a Borel set; its complement \\([1,\\infty)\\) is then a Borel set (by property 3 of sigma algebras). Then \\((-\\infty,0) \\cup [1,\\infty)\\) is a Borel set as a countable union of Borel sets. Finally, its complement \\([0,1)\\) is a Borel set, as claimed.Challenge exercise 1: using a similar approach, prove that the set of irrational numbers is a Borel set. (Hint: at some point, you may want to consider a union of singleton sets \\(\\{x_0\\}\\) for certain \\(x_0 \\in \\mathbb{R}\\).) Post your solutions in the unofficial Maths @ Monash Discord!Almost any “reasonable” set you can think of will (almost surely, with probability 1!) be a Borel set (come up with your own examples and prove it), and these turn out to be precisely one broad class of sets \\(A\\) for which it makes sense to talk about the probability of the event \\(\\{X \\in A\\}\\). Now it’s time to tie this all back to probability. But to do so, we may as well (finally, for some of you) define probability rigorously…Measure and probability spacesWe define a way to assign “sizes” to measurable sets. This is the essence of measure theory.Definition 4. A measure on a measurable space \\((\\Omega,\\mathcal F)\\) is a function \\(\\mu : \\mathcal F \\to [0,\\infty]\\) (yes, we include infinity), satisfying: (Null empty set) \\(\\mu(\\varnothing) = 0\\); (Countable additivity) If \\((A_i)_{i = 1}^\\infty\\) is a countable sequence of pairwise disjoint sets (i.e. \\(A_i \\cap A_j = \\varnothing\\) for \\(i \\neq j\\)), then\\(\\mu\\left(\\bigcup_{i = 1}^\\infty A_i\\right) = \\sum_{i = 1}^\\infty \\mu(A_i)\\).Then \\((\\Omega,\\mathcal F,\\mu)\\) is a measure space. If we add the additional property that \\(\\mu(\\Omega) = 1\\), then \\(\\mu\\) is a probability measure, and \\((\\Omega,\\mathcal F,\\mu)\\) is a probability space. (In this case, we usually write \\(\\mathbb P\\) instead of \\(\\mu\\), so that \\((\\Omega,\\mathcal F,\\mathbb P)\\) is a probability space; here, \\(\\mathcal F\\) is the event space, and its elements are events.) Definition 4 (plus unit measure) is often presented as the Kolmogorov axioms for probability, covered in many (good) courses on probability at university.For example, the Lebesgue measure \\(\\lambda\\) on \\(\\mathbb{R}\\) is a way to assign lengths to subsets of the reals in a sensible way: \\(\\lambda((0,1)) = \\lambda([0,1]) = 1\\), \\(\\lambda((0,1) \\cup (3,5]) = 3\\), \\(\\lambda(\\{1,2,3,4,5\\}) = \\lambda(\\mathbb{N}) = \\lambda(\\mathbb{Q}) = 0\\), \\(\\lambda(\\mathbb{R}) = \\lambda(\\mathbb{R} \\setminus \\mathbb{Q}) = \\infty\\), etc. However, not every subset of \\(\\mathbb R\\) can be sensibly assigned a Lebesgue measure. And this is the entire point of measure theory and sigma algebras: if we did try to assign a measure to every subset, we get contradictions. And it turns out that in probability, we run into the exact same issues. When we use the usual Borel sigma algebra on the reals, we run into no such issues (intuitively because the topology is very nice, and thus the sigma algebra it contains sufficiently nice sets), and we thus stick with it.But now we turn our attention back to probability spaces. Let’s unpack this definition, at least for probability measures. Firstly, a probability is a function from the event space to \\([0,\\infty]\\) (in fact, we can see that its codomain is \\([0,1]\\), by the other properties). The probability of the empty set must be 0; this makes sense, as we always expect some outcome to occur in an experiment. The probability of the sample space is 1; again this makes sense, as the sample space is the set of all outcomes. Finally, the key property of probability is that for a (countable) sequence of pairwise disjoint events, often called mutually exclusive events, the probability of their union is the sum of their probabilities. Again, this is intuitive from elementary probability: if two events can’t happen simultaneously, we should be able to add their probabilities to get the probability of their union.Let’s firstly try our hand at proving some simple results we know from probability, using our new axioms! Let \\((\\Omega,\\mathcal F,\\mathbb P)\\) be any probability space.Proposition 5. For disjoint (mutually exclusive) \\(A,B \\in \\mathcal F\\), we have \\(\\mathbb P(A \\cup B) = \\mathbb P(A) + \\mathbb P(B)\\).Proof. Observe that the sequence \\(A,B,\\varnothing,\\varnothing,...\\) is such that any two events are pairwise disjoint. Then using property 2 of measures,\\[\\mathbb P(A \\cup B) = \\mathbb P(A \\cup B \\cup \\varnothing \\cup \\dotsb) = \\mathbb P(A) + \\mathbb P(B) + \\mathbb P(\\varnothing) + \\dotsb = \\mathbb P(A) + \\mathbb P(B),\\]where we use the fact that \\(\\mathbb P(\\varnothing) = 0\\), i.e. property 1 of measures. \\(\\square\\)Proposition 6. For \\(A \\in \\mathcal F\\), we have \\(\\mathbb P(A^c) = 1 - \\mathbb P(A)\\).Proof. Observe that \\(A,A^c\\) are disjoint, and \\(A \\cup A^c = \\Omega\\). Then by Proposition 5,\\[1 = \\mathbb P(\\Omega) = \\mathbb P(A \\cup A^c) = \\mathbb P(A) + \\mathbb P(A^c),\\]so \\(\\mathbb P(A^c) = 1 - \\mathbb P(A)\\), as claimed. \\(\\square\\)Challenge question 2.1. Prove that for any \\(A,B \\in \\mathcal F\\) (not necessarily disjoint), we have \\(\\mathbb P(A \\cup B) = \\mathbb P(A) + \\mathbb P(B) - \\mathbb P(A \\cap B)\\). (Hint: decompose \\(A \\cup B\\) into two disjoint events in \\(\\mathcal F\\).)Challenge question 2.2 (conditional probability). Fix \\(E \\in \\mathcal F\\) with \\(\\mathbb P(E) \\neq 0\\), where \\((\\Omega,\\mathcal F,\\mathbb P)\\) is a probability space. Consider the collection of sets \\(\\mathcal F_E := \\{E \\cap A : A \\in \\mathcal F\\}\\). Show that \\(\\mathcal F_E\\) is a sigma algebra on \\(E\\). Define a function \\(\\mathbb P_E : \\mathcal F_E \\to [0,1]\\) by\\(\\mathbb P_E(B) = \\frac{\\mathbb P(B)}{\\mathbb P(E)}.\\)Show that this is a probability measure on \\((E,\\mathcal F_E)\\), i.e. \\((E,\\mathcal F_E,\\mathbb P_E)\\) is a probability space.Note that \\(B \\in \\mathcal F_E\\) means that \\(B = A \\cap E\\) for some \\(A \\in \\mathcal F\\), so \\(\\mathbb P_E(B) = \\frac{\\mathbb P(A \\cap E)}{\\mathbb P(E)}\\); we often use the notation \\(\\mathbb P(A \\mid E) = \\mathbb P_E(A \\cap E)\\). This is called conditional probability: essentially, we restrict our event space to events that intersect the conditioning event \\(E\\), and reweight all probabilities so that we still have a valid probability measure (with \\(\\mathbb P_E(E) = 1\\)).Examples of probability spacesNote that the probability measure \\(\\mathbb P\\) is extremely abstract: once we have decided on a sample space, that is, a set of possible outcomes, any function \\(\\mathbb{P} : \\mathcal F \\to [0,1]\\) satisfying the above properties of a measure, defines a “probability” on \\(\\Omega\\). This probability may range from something usual, to something wild. We consider a few simple examples:Example 7 (rolling two independent fair dice). Here, a possible sample space is \\(\\Omega = \\{1,...,6\\} \\times \\{1,...,6\\}\\), i.e. ordered pairs of numbers in \\(1,...,6\\). This naturally encodes the outcome of a sequence of two dice rolls. Now what are the valid events? Since the sample space has \\(36\\) elements (and is finite), we may take \\(\\mathcal F = \\mathcal P(\\Omega)\\), the power set of the sample space; that is, every subset of \\(\\Omega\\) is a valid event. (You can check that this is indeed a sigma algebra on \\(\\Omega\\). How many events are there in total?)Now we consider the probability measure \\(\\mathbb P : \\mathcal F \\to [0,1]\\). Note that every event \\(A\\) is a (countable) union of individual outcomes \\(\\omega \\in \\Omega\\). By our assumption of fairness and independence (which gives symmetry), each of the 36 possible outcomes is assigned a measure of \\(\\frac{1}{36}\\), so that \\(\\mathbb P(\\Omega) = 1\\). Thus, for \\(A \\in \\mathcal F\\), its probability depends only on its cardinality: in fact,\\[\\mathbb P(A) = \\mathbb P\\left(\\bigcup_{\\omega \\in A} \\{\\omega\\}\\right) = \\sum_{\\omega \\in A} \\mathbb P(\\{\\omega\\}) = \\sum_{\\omega \\in A} \\frac{1}{36} = \\frac{|A|}{36};\\]this fully specifies the probability space in this experiment. (Note that in this derivation, we assumed that \\(\\mathbb P\\) was a probability measure, to get countable additivity.)Example 8 (independently tossing a sequence of coins). Here, a possible sample space is \\(\\{0,1\\}^\\infty\\), the space of infinite sequences with terms in \\(\\{0,1\\}\\), where we may associate \\(0\\) with a tails, and \\(1\\) with a heads. In this case, an appropriate event space \\(\\mathcal F\\) is more complicated. For a finite binary string \\(b = b_1\\dotsb b_n\\), define\\[A_b = \\{(b_1,b_2,...,b_n,x_{n+1},x_{n+2},...) : x_{n+1},x_{n+2},... \\in \\{0,1\\}\\}.\\]Then for natural \\(n \\geq 0\\), define \\(\\mathcal F_n := \\{\\varnothing,\\Omega\\} \\cup \\{A_b : b\\ \\text{is a binary string of length at most}\\ n\\}\\). For example, \\(\\mathcal F_2 := \\{\\varnothing,\\Omega,A_0,A_1,A_{00},A_{01},A_{10},A_{11}\\}\\). Define \\(\\mathcal F\\) as the smallest sigma algebra containing \\(\\bigcup_{n = 0}^\\infty \\mathcal F_n\\) (the union turns out to not be a sigma algebra, as seen here). We need this construction, instead of the entire power set of \\(\\Omega\\), as there turn out to be subsets of \\(\\Omega\\) that cannot be assigned a measure in a way that agrees with our definition!Now suppose that for each toss, a head appears with probability \\(p \\in (0,1)\\). For integer \\(n \\geq 1\\), let \\(B_n\\) be the event that the first head is tossed on the \\(n\\)th toss: then\\[B_n = \\{(\\underbrace{0,0,...,0,1}_{n\\ \\text{tosses}},x_{n+1},x_{n+2},...) : x_{n+1},x_{n+2},... \\in \\{0,1\\}\\};\\]this is precisely the event \\(A_{00\\dotsb 1}\\) defined above, so we know that \\(B_n\\) is a valid event (i.e. \\(B_n \\in \\mathcal F\\)), by construction.Challenge question 3 (related to example 8). If a random variable \\(X\\) is defined on \\(\\mathbb{Z}^+\\) such that the event \\(\\{X = n\\} = B_n\\) (i.e. \\(\\mathbb P(X = n) = \\mathbb P(B_n)\\)): What is the well-known distribution of \\(X\\)? Thus, what should \\(\\mathbb P\\) assign to this event \\(B_n\\)? Show that each singleton set (containing a single sequence of tosses) is in the event space, so that it makes sense to talk about its probability. What is this probability of any individual sequence \\(\\omega = (x_1,x_2,...)\\) of tosses in \\(B_n\\)? Is \\(\\mathbb P(B_n) = \\mathbb P\\left(\\bigcup_{\\omega \\in B_n} \\{\\omega\\}\\right) = \\sum_{\\omega \\in B_n} \\mathbb P(\\{\\omega\\})\\), and is this a contradiction, since the \\(B_n\\) are pairwise disjoint and we expect the probability of the union to be the sum of the probabilities? (Hint: what is \\(\\lvert B_n \\rvert\\)? Can you show that it is uncountable? Consider Cantor’s diagonalisation argument.)Post your solutions in the unofficial Maths @ Monash Discord!In this previous example, we saw an example of an event with probability 0, but is certainly possible: of course, the event of any particular sequence of heads/tails is a possible outcome.Example 9 (uniform distribution on unit interval). In this example, \\(\\Omega = [0,1]\\). Imagine randomly selecting a number in \\([0,1]\\); random number generators do this (pseudorandomly) all the time. What is the probability of getting a particular number \\(\\omega \\in [0,1]\\)? (We’ll answer this later.) Let’s firstly consider the event space. It turns out the power set of \\([0,1]\\) is too big (we cannot define a probability measure on it); this is where we use the Borel sigma algebra! Recall the Borel sets in \\(\\mathbb R\\). We say that \\(A \\subseteq [0,1]\\) is a Borel set (in \\([0,1]\\)) if it is a Borel set in \\(\\mathbb R\\), under the usual topology (open sets contain open intervals about every point). So \\(\\mathcal F = \\mathcal B\\); for example, \\([0,1],(0,1),(1/2,3/4),\\mathbb Q \\cap [0,1]\\) are all valid events.We define \\(\\mathbb P : \\mathcal F \\to [0,1]\\) in a natural way: for any open interval \\(I = (a,b) \\subseteq [0,1]\\), we define \\(\\mathbb P(I) = b - a\\). Moreover, define \\(\\mathbb P([0,a)) = a\\) and \\(\\mathbb P((a,1]) = 1 - a\\) for \\(a \\in (0,1)\\). This then extends to all the other Borel sets via the properties of a probability measure (invoking the Hahn-Kolmogorov theorem). The intuition behind this is that probability should be proportional to the length/size, or Lebesgue measure, of the set. For example, the probability of \\(A = \\{0,1/2\\}\\) is \\(0\\): \\(A^c = (0,1/2) \\cup (1/2,1]\\). We defined \\(\\mathbb P((0,1/2)) = \\mathbb P((1/2,1]) = 1/2\\). Therefore,\\[\\mathbb P(A^c) = \\mathbb P\\left(\\left(0,\\frac{1}{2}\\right) \\cup \\left(\\frac{1}{2},1\\right]\\right) = \\mathbb P\\left(\\left(0,\\frac{1}{2}\\right)\\right) + \\mathbb P\\left(\\left(\\frac{1}{2},1\\right]\\right) = \\frac{1}{2} + \\frac{1}{2} = 1,\\]meaning that \\(\\mathbb P(A) = 0\\). Again, this is an event that is possible (we can pick \\(0\\) or \\(1/2\\) randomly, but the probability is \\(0\\).)As another example, we compute \\(\\mathbb P(\\mathbb A \\cap \\Omega)\\), where \\(\\mathbb A \\subseteq \\mathbb C\\) is the set of algebraic numbers, i.e. roots of polynomials with integer coefficients. By the fundamental theorem of algebra, a degree \\(n\\) polynomial has at most \\(n\\) roots. By identifying the degree-\\(n\\) polynomial \\(p(x) = a_0 + a_1x + \\dotsb + a_nx^n \\in \\mathbb Z[x]\\) with the sequence \\((a_0,a_1,...,a_n) \\in \\mathbb Z^n\\) and taking a union over all \\(n \\in \\mathbb N\\), it is possible to see that the set of polynomials \\(\\mathbb Z[x]\\) with integral coefficients is countable. Thus there are at most a countable number of algebraic numbers (by counting the roots as you count these polynomials). As shown in the following challenge question, \\(\\mathbb P(\\{x\\}) = 0\\) for any \\(x \\in [0,1]\\). Since \\(\\mathbb A \\cap \\Omega\\) is a countable union of such singleton sets, it follows by countable additivity that \\(\\mathbb P(\\mathbb A \\cap \\Omega) = 0\\).Challenge question 4 (related to example 9). Show, using only the properties of a probability measure, that for any \\(x \\in [0,1]\\), \\(\\mathbb P(\\{x\\}) = 0\\). Thus show that \\(\\mathbb P([a,b]) = b - a\\) for closed intervals \\([a,b] \\subseteq [0,1]\\) with \\(a \\neq 0\\) and \\(b \\neq 1\\) (although it is true for those too). It is known that \\(B = \\sin^2(\\mathbb N) = \\{\\sin^2(n) : n \\in \\mathbb N\\}\\) (where \\(0 \\in \\mathbb N\\)) is dense in \\([0,1]\\) (meaning that you can find points in \\(B\\) within any (possibly arbitrary small) open subinterval of \\([0,1]\\)); find the probability that you do not randomly choose a number in \\(B\\), i.e. \\(\\mathbb P(\\Omega \\setminus B)\\).Post your solutions in the unofficial Maths @ Monash Discord!We’ve now had quite a bit of experience with probability spaces, and maybe you can start to appreciate the role of measure theory in probability! Now we are finally ready, and will attempt to answer the age-old question: what is a random variable? Check out the next post for the answers!" } ]
