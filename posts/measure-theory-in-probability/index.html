<!DOCTYPE html><html lang="en-AU" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.1" /><meta property="og:title" content="Why probability and statistics need measure theory, part 1" /><meta property="og:locale" content="en_AU" /><meta name="description" content="Introduction to the problem" /><meta property="og:description" content="Introduction to the problem" /><link rel="canonical" href="https://subjunctivequaver.github.io//posts/measure-theory-in-probability/" /><meta property="og:url" content="https://subjunctivequaver.github.io//posts/measure-theory-in-probability/" /><meta property="og:site_name" content="Epic Maths Time" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-06-16T21:57:00+10:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Why probability and statistics need measure theory, part 1" /><meta name="twitter:site" content="@SubjunctiveQuav" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-07-05T22:54:22+10:00","datePublished":"2021-06-16T21:57:00+10:00","description":"Introduction to the problem","headline":"Why probability and statistics need measure theory, part 1","mainEntityOfPage":{"@type":"WebPage","@id":"https://subjunctivequaver.github.io//posts/measure-theory-in-probability/"},"url":"https://subjunctivequaver.github.io//posts/measure-theory-in-probability/"}</script><title>Why probability and statistics need measure theory, part 1 | Epic Maths Time</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Epic Maths Time"><meta name="application-name" content="Epic Maths Time"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://raw.githubusercontent.com/SubjunctiveQuaver/subjunctivequaver.github.io/main/SubjunctiveQuaver.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Epic Maths Time</a></div><div class="site-subtitle font-italic">Lawrence's blog on epic mathematical tidbits!</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/SubjunctiveQuaver" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/SubjunctiveQuav" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['lawrence.d.chen','outlook.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <a href="https://www.linkedin.com/in/lawrencechen11/" aria-label="linkedin" class="order-7" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="" aria-label="" class="order-8" target="_blank" rel="noopener"> <i class=""></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Why probability and statistics need measure theory, part 1</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Why probability and statistics need measure theory, part 1</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Lawrence Chen </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Jun 16, 2021, 9:57 PM +1000" >Jun 16, 2021<i class="unloaded">2021-06-16T21:57:00+10:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Jul 5, 2021, 10:54 PM +1000" >Jul 5, 2021<i class="unloaded">2021-07-05T22:54:22+10:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3539 words">19 min read</span></div></div><div class="post-content"><h2 id="introduction-to-the-problem">Introduction to the problem</h2><p>You may have encountered continuous probability distributions such as the normal distribution. It’s often used to model things in the real world, and has nice statistical properties. You know the bell curve. But what you may not have seen is its formula: the <em>probability density function</em> (often shortened to just <em>density</em>),</p>\[f_\theta : \mathbb{R} \to \mathbb{R}, \quad x \mapsto \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)\]<p>given a value of \(\theta = (\mu,\sigma^2) \in \Theta\). In our case, \(\Theta = \mathbb{R} \times (0,\infty)\); this is known as the <em>parameter space</em>, and this is central to the study of statistics.</p><p><img data-proofer-ignore data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/2880px-Standard_deviation_diagram.svg.png" alt="The probability density function of a normally distributed random variable." /></p><p>How does this relate to probability? Well, everything. We begin informally: suppose that \(X\) is a continuous random variable with density \(f_\theta\). The meaning of this is unimportant initially; think of \(X\) as a “variable” that takes on values randomly (we will see that this is very much <em>not</em> a random variable <em>should</em> be). For a “reasonable” subset \(A \subseteq \mathbb{R}\), let \(\mathbb{P}(X \in A)\) denote the probability that \(X \in A\), i.e. the probability of the event \(\{X \in A\}\) (whatever that means). It turns out that, and as is often taught in a class in probability (even at high school level),</p>\[\mathbb P(X \in A) = \int_A f_\theta(x)\,dx = \int_A \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)\,dx.\]<p>In fact, we are kind of working backwards. The probability density function is essentially defined to be a function such that integrating it over the desired subset yields the probability of \(X\) taking on a value in that set. We get a couple of questions:</p><ol><li>How does the probability-assignment process work?<li>What should \(A\) be allowed to be? Should we allow <em>every</em> subset of the reals?<li>In particular, if \(A = \{x_0\}\) for some \(x_0 \in \mathbb{R}\), the previous formula implies that \(\mathbb P(X = x_0) = 0\), as an integral over a point. Does that make sense? Does that mean the event \(\{X = x_0\}\) is impossible? (It turns out it <em>is</em> possible!)<li>Also, what about the seemingly irreconcilable differences between continuous and discrete probability distributions (density vs mass, expectation formulas, the general vibe, etc.)?</ol><p>It turns out that <em>measure theory</em> has the answer to all of these questions.</p><h2 id="some-measure-theory-with-a-probabilistic-flavour">Some measure theory, with a probabilistic flavour</h2><h3 id="topologies-and-sigma-algebras">Topologies and sigma algebras</h3><p>Measure theory is essentially the theory of assigning sizes to sets, done rigorously. We will motivate probability spaces, which are measure spaces in which the “total size” is 1. But first, we define a <em>topology</em>; it turns out that it is intimately related to measures. (<em>Warning:</em> this subsection is rather technical, so feel free to skim over it; it’s mostly here for background.)</p><p><strong>Definition 1.</strong> Let \(\Omega\) be a set, called the <strong>sample space</strong> in our context. A <strong>topology</strong> on \(\Omega\) is a collection \(\tau\) of subsets of \(\Omega\) satisfying the following properties:</p><ol><li><strong>(Whole and empty set)</strong> The whole and empty sets are elements of the topology: \(\Omega \in \tau\) and \(\varnothing \in \tau\);<li><strong>(Closure under arbitrary unions)</strong> For an indexed collection of sets \((A_i)_{i \in I}\) with each \(A_i \in \tau\) (finite or infinite), their union \(\bigcup_{i \in I} A_i \in \tau\) also;<li><strong>(Closure under finite intersections)</strong> For a finite collection of sets \(A_1,A_2,...,A_n\) with each \(A_i \in \tau\), their intersection \(\bigcap_{i = 1}^n A_i \in \tau\) also.</ol><p>If \(\tau\) is a topology on \(\Omega\), then the pair \((\Omega,\tau)\) is a <strong>topological space</strong>, and the elements in the topology (subsets of \(\Omega\)) are called <strong>open sets</strong>. A set \(B\) is <strong>closed</strong> if \(\Omega \setminus B\) is open.</p><p>Yes, this is the <em>topology</em> in which donuts are the same as (homeomorphic to) coffee mugs!</p><p><img data-proofer-ignore data-src="https://upload.wikimedia.org/wikipedia/commons/2/26/Mug_and_Torus_morph.gif" alt="Classic image of a mug and torus morphing into each other, from Wikipedia." /></p><p>Let’s look at a simple example of a topological space: the usual one \((\mathbb{R},\tau)\) on the reals. We define it via the open sets: a subset \(A \subseteq \mathbb{R}\) is <em>open</em> if, for <em>each</em> point \(a \in A\), there is an open interval \(I = (a - \epsilon,a + \epsilon)\) (with \(\epsilon &gt; 0\)) centred at \(a\) that is wholly contained in \(A\), i.e. \(I \subseteq A\). For example, the set \(\mathbb{R}\) is open: for \(a \in \mathbb{R}\), we have \((a - 1,a + 1) \subseteq \mathbb{R}\). Additionally, the set \((0,1)\) is open: for \(a \in (0,1)\), let \(\epsilon = \min(a,1 - a) \leq a,1 - a\); note that \(0 = a - a \leq a - \epsilon\) and \(a + \epsilon \leq a + (1 - a) = 1\), so \((a - \epsilon,a + \epsilon) \subseteq (0,1)\). However, the set \([0,1)\) is not open: at \(a = 0\), <em>every</em> open interval centred at \(0\) goes “outside” of \((0,1)\). From these, we see that \(\mathbb R \setminus \mathbb R = \varnothing\) and \(\mathbb R \setminus (0,1) = (-\infty,0] \cup [1,\infty)\) are <em>closed</em>. A similar argument shows that \([0,1]\) is closed (its complement is open); this suggests that the <em>intervals</em> that are open sets are precisely the open intervals \((a,b)\), and those that are closed sets are precisely the closed intervals \([a,b]\) (where we allow infinity and \(a = b\)).</p><p>Now back to our question: which sets can we talk about probabilities of? Suppose that we only allowed open and closed sets. Then sets as simple as \([0,1)\) would be disallowed, but it seems quite reasonable to talk about the probability of \(\{0 \leq X &lt; 1\}\)! Thus we introduce sigma algebras:</p><p><strong>Definition 2.</strong> Let \(\Omega\) be a set, called the <strong>sample space</strong> in our context. A <strong>sigma algebra (of sets)</strong> on \(\Omega\) is a collection \(\mathcal F\) of subsets of \(\Omega\) satisfying the following properties:</p><ol><li><strong>(Whole and empty set)</strong> The whole and empty sets are elements of the sigma algebra: \(\Omega \in \mathcal F\) and \(\varnothing \in \mathcal F\) (we may omit one of these);<li><strong>(Closure under countable unions)</strong> For a countable collection of sets \((A_i)_{i = 1}^\infty\) with each \(A_i \in \mathcal F\), their union \(\bigcup_{i = 1}^\infty A_i \in \mathcal F\) also;<li><strong>(Closure under complements)</strong> If \(A \in \mathcal F\), then its <strong>complement</strong> \(A^c := \Omega \setminus A \in \mathcal F\).</ol><p>If \(\mathcal F\) is a sigma algebra on \(\Omega\), then the pair \((\Omega,\mathcal F)\) is a <strong>measurable space</strong>, and the elements in the sigma algebra (subsets of \(\Omega\)) are called <strong>measurable sets</strong>; in the context of probability, we call them <strong>events</strong>.</p><p>Note that by de Morgan’s laws, we also have closure under countable intersections: if \(A_1,A_2,... \in \mathcal F\), then \(A_1^c,A_2^c,... \in \mathcal F\); then \(\bigcup_{i = 1}^\infty A_i^c = \left(\bigcap_{i = 1}^\infty A_i\right)^c \in \mathcal F\), so its complement \(\bigcap_{i = 1}^\infty A_i \in \mathcal F\).</p><p>Now, what’s an example of a sigma algebra on the reals? For this, essentially take our standard topology from above, and just force it to be a sigma algebra: this gives the <em>Borel sigma algebra</em>.</p><p><strong>Definition 3.</strong> Let \((\Omega,\tau)\) be a topological space. The <strong>Borel sigma algebra</strong> \(\mathcal B = \mathcal B(\tau)\) is the (smallest) sigma algebra generated by \(\tau\), formed from a countable number of unions, intersections, and complements of open sets in \(\Omega\). Elements of \(\mathcal B\) are then called <strong>Borel sets</strong>.</p><p>For example, \([0,1)\) is a Borel set. Why? Notice that \([0,1) = [(-\infty,0) \cup [1,\infty)]^c\). Since \((-\infty,0)\) is open, it must be a Borel set (as the Borel sigma algebra contains the topology). Also, since \((-\infty,1)\) is open, it too is a Borel set; its complement \([1,\infty)\) is then a Borel set (by property 3 of sigma algebras). Then \((-\infty,0) \cup [1,\infty)\) is a Borel set as a countable union of Borel sets. Finally, its complement \([0,1)\) is a Borel set, as claimed.</p><p><strong>Challenge exercise 1:</strong> using a similar approach, prove that the set of irrational numbers is a Borel set. (<em>Hint:</em> at some point, you may want to consider a union of singleton sets \(\{x_0\}\) for certain \(x_0 \in \mathbb{R}\).) Post your solutions in the unofficial <a href="https://discord.gg/hx63ZwSXBg">Maths @ Monash Discord</a>!</p><p>Almost any “reasonable” set you can think of will (almost surely, with probability 1!) be a Borel set (come up with your own examples and prove it), and these turn out to be precisely one broad class of sets \(A\) for which it makes sense to talk about the probability of the event \(\{X \in A\}\). Now it’s time to tie this all back to probability. But to do so, we may as well (finally, for some of you) define probability rigorously…</p><h3 id="measure-and-probability-spaces">Measure and probability spaces</h3><p>We define a way to assign “sizes” to measurable sets. This is the essence of measure theory.</p><p><strong>Definition 4.</strong> A <strong>measure</strong> on a measurable space \((\Omega,\mathcal F)\) is a function \(\mu : \mathcal F \to [0,\infty]\) (yes, we include infinity), satisfying:</p><ol><li><strong>(Null empty set)</strong> \(\mu(\varnothing) = 0\);<li><strong>(Countable additivity)</strong> If \((A_i)_{i = 1}^\infty\) is a countable sequence of pairwise disjoint sets (i.e. \(A_i \cap A_j = \varnothing\) for \(i \neq j\)), then \(\mu\left(\bigcup_{i = 1}^\infty A_i\right) = \sum_{i = 1}^\infty \mu(A_i)\).</ol><p>Then \((\Omega,\mathcal F,\mu)\) is a <strong>measure space</strong>. If we add the additional property that \(\mu(\Omega) = 1\), then \(\mu\) is a <strong>probability measure</strong>, and \((\Omega,\mathcal F,\mu)\) is a <strong>probability space</strong>. (In this case, we usually write \(\mathbb P\) instead of \(\mu\), so that \((\Omega,\mathcal F,\mathbb P)\) is a probability space; here, \(\mathcal F\) is the <strong>event space</strong>, and its elements are <strong>events</strong>.) Definition 4 (plus unit measure) is often presented as the <strong>Kolmogorov axioms</strong> for probability, covered in many (good) courses on probability at university.</p><p>For example, the <em>Lebesgue measure</em> \(\lambda\) on \(\mathbb{R}\) is a way to assign lengths to subsets of the reals in a sensible way: \(\lambda((0,1)) = \lambda([0,1]) = 1\), \(\lambda((0,1) \cup (3,5]) = 3\), \(\lambda(\{1,2,3,4,5\}) = \lambda(\mathbb{N}) = \lambda(\mathbb{Q}) = 0\), \(\lambda(\mathbb{R}) = \lambda(\mathbb{R} \setminus \mathbb{Q}) = \infty\), etc. However, not <em>every</em> subset of \(\mathbb R\) can be sensibly assigned a Lebesgue measure. And this is the entire point of measure theory and sigma algebras: if we did try to assign a measure to <em>every</em> subset, we get <a href="https://en.wikipedia.org/wiki/Vitali_set">contradictions</a>. And it turns out that in probability, we run into the exact same issues. When we use the usual Borel sigma algebra on the reals, we run into no such issues (intuitively because the topology is very nice, and thus the sigma algebra it contains sufficiently nice sets), and we thus stick with it.</p><p>But now we turn our attention back to probability spaces. Let’s unpack this definition, at least for probability measures. Firstly, a probability is a function from the <em>event space</em> to \([0,\infty]\) (in fact, we can see that its codomain is \([0,1]\), by the other properties). The probability of the empty set must be 0; this makes sense, as we always expect some outcome to occur in an experiment. The probability of the sample space is 1; again this makes sense, as the sample space is the set of all outcomes. Finally, the key property of probability is that for a (countable) sequence of pairwise <em>disjoint</em> events, often called <strong>mutually exclusive</strong> events, the probability of their union is the sum of their probabilities. Again, this is intuitive from elementary probability: if two events can’t happen simultaneously, we should be able to add their probabilities to get the probability of their union.</p><p>Let’s firstly try our hand at proving some simple results we know from probability, using our new axioms! Let \((\Omega,\mathcal F,\mathbb P)\) be <em>any</em> probability space.</p><p><strong>Proposition 5.</strong> For disjoint (mutually exclusive) \(A,B \in \mathcal F\), we have \(\mathbb P(A \cup B) = \mathbb P(A) + \mathbb P(B)\).</p><p><em>Proof.</em> Observe that the sequence \(A,B,\varnothing,\varnothing,...\) is such that any two events are pairwise disjoint. Then using property 2 of measures,</p>\[\mathbb P(A \cup B) = \mathbb P(A \cup B \cup \varnothing \cup \dotsb) = \mathbb P(A) + \mathbb P(B) + \mathbb P(\varnothing) + \dotsb = \mathbb P(A) + \mathbb P(B),\]<p>where we use the fact that \(\mathbb P(\varnothing) = 0\), i.e. property 1 of measures. \(\square\)</p><p><strong>Proposition 6.</strong> For \(A \in \mathcal F\), we have \(\mathbb P(A^c) = 1 - \mathbb P(A)\).</p><p><em>Proof.</em> Observe that \(A,A^c\) are disjoint, and \(A \cup A^c = \Omega\). Then by Proposition 5,</p>\[1 = \mathbb P(\Omega) = \mathbb P(A \cup A^c) = \mathbb P(A) + \mathbb P(A^c),\]<p>so \(\mathbb P(A^c) = 1 - \mathbb P(A)\), as claimed. \(\square\)</p><p><strong>Challenge question 2.1.</strong> Prove that for <em>any</em> \(A,B \in \mathcal F\) (not necessarily disjoint), we have \(\mathbb P(A \cup B) = \mathbb P(A) + \mathbb P(B) - \mathbb P(A \cap B)\). (<em>Hint:</em> decompose \(A \cup B\) into two disjoint events in \(\mathcal F\).)</p><p><strong>Challenge question 2.2 (conditional probability).</strong> Fix \(E \in \mathcal F\) with \(\mathbb P(E) \neq 0\), where \((\Omega,\mathcal F,\mathbb P)\) is a probability space.</p><ol><li>Consider the collection of sets \(\mathcal F_E := \{E \cap A : A \in \mathcal F\}\). Show that \(\mathcal F_E\) is a sigma algebra on \(E\).<li>Define a function \(\mathbb P_E : \mathcal F_E \to [0,1]\) by \(\mathbb P_E(B) = \frac{\mathbb P(B)}{\mathbb P(E)}.\) Show that this is a probability measure on \((E,\mathcal F_E)\), i.e. \((E,\mathcal F_E,\mathbb P_E)\) is a probability space.</ol><p>Note that \(B \in \mathcal F_E\) means that \(B = A \cap E\) for some \(A \in \mathcal F\), so \(\mathbb P_E(B) = \frac{\mathbb P(A \cap E)}{\mathbb P(E)}\); we often use the notation \(\mathbb P(A \mid E) = \mathbb P_E(A \cap E)\). This is called <strong>conditional probability</strong>: essentially, we restrict our event space to events that intersect the conditioning event \(E\), and reweight all probabilities so that we still have a valid probability measure (with \(\mathbb P_E(E) = 1\)).</p><h3 id="examples-of-probability-spaces">Examples of probability spaces</h3><p>Note that the probability measure \(\mathbb P\) is extremely abstract: once we have decided on a <em>sample space</em>, that is, a set of possible outcomes, <em>any</em> function \(\mathbb{P} : \mathcal F \to [0,1]\) satisfying the above properties of a measure, defines a “probability” on \(\Omega\). This probability may range from something usual, to something wild. We consider a few simple examples:</p><p><strong>Example 7 (rolling two independent fair dice).</strong> Here, a possible sample space is \(\Omega = \{1,...,6\} \times \{1,...,6\}\), i.e. ordered pairs of numbers in \(1,...,6\). This naturally encodes the outcome of a sequence of two dice rolls. Now what are the valid events? Since the sample space has \(36\) elements (and is finite), we may take \(\mathcal F = \mathcal P(\Omega)\), the power set of the sample space; that is, every subset of \(\Omega\) is a valid event. (You can check that this is indeed a sigma algebra on \(\Omega\). How many events are there in total?)</p><p>Now we consider the probability measure \(\mathbb P : \mathcal F \to [0,1]\). Note that every event \(A\) is a (countable) union of individual outcomes \(\omega \in \Omega\). By our assumption of fairness and independence (which gives symmetry), each of the 36 possible outcomes is assigned a measure of \(\frac{1}{36}\), so that \(\mathbb P(\Omega) = 1\). Thus, for \(A \in \mathcal F\), its probability depends only on its cardinality: in fact,</p>\[\mathbb P(A) = \mathbb P\left(\bigcup_{\omega \in A} \{\omega\}\right) = \sum_{\omega \in A} \mathbb P(\{\omega\}) = \sum_{\omega \in A} \frac{1}{36} = \frac{|A|}{36};\]<p>this fully specifies the probability space in this experiment. (Note that in this derivation, we assumed that \(\mathbb P\) was a probability measure, to get countable additivity.)</p><p><strong>Example 8 (independently tossing a sequence of coins).</strong> Here, a possible sample space is \(\{0,1\}^\infty\), the space of infinite sequences with terms in \(\{0,1\}\), where we may associate \(0\) with a tails, and \(1\) with a heads. In this case, an appropriate <a href="https://math.stackexchange.com/questions/1457569/question-about-the-sigma-algebra-for-infinite-coin-toss">event space</a> \(\mathcal F\) is more complicated. For a finite binary string \(b = b_1\dotsb b_n\), define</p>\[A_b = \{(b_1,b_2,...,b_n,x_{n+1},x_{n+2},...) : x_{n+1},x_{n+2},... \in \{0,1\}\}.\]<p>Then for natural \(n \geq 0\), define \(\mathcal F_n := \{\varnothing,\Omega\} \cup \{A_b : b\ \text{is a binary string of length at most}\ n\}\). For example, \(\mathcal F_2 := \{\varnothing,\Omega,A_0,A_1,A_{00},A_{01},A_{10},A_{11}\}\). Define \(\mathcal F\) as the smallest sigma algebra containing \(\bigcup_{n = 0}^\infty \mathcal F_n\) (the union turns out to not be a sigma algebra, as seen <a href="https://math.stackexchange.com/questions/1457569/question-about-the-sigma-algebra-for-infinite-coin-toss">here</a>). We need this construction, instead of the entire power set of \(\Omega\), as there turn out to be subsets of \(\Omega\) that <a href="https://math.stackexchange.com/a/1457657/">cannot be assigned a measure</a> in a way that agrees with our definition!</p><p>Now suppose that for each toss, a head appears with probability \(p \in (0,1)\). For integer \(n \geq 1\), let \(B_n\) be the event that the first head is tossed on the \(n\)th toss: then</p>\[B_n = \{(\underbrace{0,0,...,0,1}_{n\ \text{tosses}},x_{n+1},x_{n+2},...) : x_{n+1},x_{n+2},... \in \{0,1\}\};\]<p>this is precisely the event \(A_{00\dotsb 1}\) defined above, so we know that \(B_n\) is a valid event (i.e. \(B_n \in \mathcal F\)), by construction.</p><p><strong>Challenge question 3 (related to example 8).</strong> If a random variable \(X\) is defined on \(\mathbb{Z}^+\) such that the event \(\{X = n\} = B_n\) (i.e. \(\mathbb P(X = n) = \mathbb P(B_n)\)):</p><ol><li>What is the well-known distribution of \(X\)?<li>Thus, what should \(\mathbb P\) assign to this event \(B_n\)?<li>Show that each singleton set (containing a single sequence of tosses) is in the event space, so that it makes sense to talk about its probability. What is this probability of any individual sequence \(\omega = (x_1,x_2,...)\) of tosses in \(B_n\)?<li>Is \(\mathbb P(B_n) = \mathbb P\left(\bigcup_{\omega \in B_n} \{\omega\}\right) = \sum_{\omega \in B_n} \mathbb P(\{\omega\})\), and is this a contradiction, since the \(B_n\) are pairwise disjoint and we expect the probability of the union to be the sum of the probabilities? (<em>Hint:</em> what is \(\lvert B_n \rvert\)? Can you show that it is <em>uncountable</em>? Consider Cantor’s diagonalisation argument.)</ol><p>Post your solutions in the unofficial <a href="https://discord.gg/hx63ZwSXBg">Maths @ Monash Discord</a>!</p><p>In this previous example, we saw an example of an event with probability 0, but is certainly possible: of course, the event of any particular sequence of heads/tails is a possible outcome.</p><p><strong>Example 9 (uniform distribution on unit interval).</strong> In this example, \(\Omega = [0,1]\). Imagine randomly selecting a number in \([0,1]\); random number generators do this (pseudorandomly) all the time. What is the probability of getting a particular number \(\omega \in [0,1]\)? (We’ll answer this later.) Let’s firstly consider the event space. It turns out the power set of \([0,1]\) is too big (we cannot define a probability measure on it); this is where we use the <em>Borel sigma algebra</em>! Recall the Borel sets in \(\mathbb R\). We say that \(A \subseteq [0,1]\) is a Borel set (in \([0,1]\)) if it is a Borel set in \(\mathbb R\), under the usual topology (open sets contain open intervals about every point). So \(\mathcal F = \mathcal B\); for example, \([0,1],(0,1),(1/2,3/4),\mathbb Q \cap [0,1]\) are all valid events.</p><p>We define \(\mathbb P : \mathcal F \to [0,1]\) in a natural way: for any open interval \(I = (a,b) \subseteq [0,1]\), we define \(\mathbb P(I) = b - a\). Moreover, define \(\mathbb P([0,a)) = a\) and \(\mathbb P((a,1]) = 1 - a\) for \(a \in (0,1)\). This then extends to all the other Borel sets via the properties of a probability measure (invoking the <a href="https://handwiki.org/wiki/Hahn%E2%80%93Kolmogorov_theorem">Hahn-Kolmogorov theorem</a>). The intuition behind this is that probability should be proportional to the length/size, or <em>Lebesgue measure</em>, of the set. For example, the probability of \(A = \{0,1/2\}\) is \(0\): \(A^c = (0,1/2) \cup (1/2,1]\). We defined \(\mathbb P((0,1/2)) = \mathbb P((1/2,1]) = 1/2\). Therefore,</p>\[\mathbb P(A^c) = \mathbb P\left(\left(0,\frac{1}{2}\right) \cup \left(\frac{1}{2},1\right]\right) = \mathbb P\left(\left(0,\frac{1}{2}\right)\right) + \mathbb P\left(\left(\frac{1}{2},1\right]\right) = \frac{1}{2} + \frac{1}{2} = 1,\]<p>meaning that \(\mathbb P(A) = 0\). Again, this is an event that is possible (we <em>can</em> pick \(0\) or \(1/2\) randomly, but the <em>probability</em> is \(0\).)</p><p>As another example, we compute \(\mathbb P(\mathbb A \cap \Omega)\), where \(\mathbb A \subseteq \mathbb C\) is the set of algebraic numbers, i.e. roots of polynomials with <em>integer</em> coefficients. By the fundamental theorem of algebra, a degree \(n\) polynomial has at most \(n\) roots. By identifying the degree-\(n\) polynomial \(p(x) = a_0 + a_1x + \dotsb + a_nx^n \in \mathbb Z[x]\) with the sequence \((a_0,a_1,...,a_n) \in \mathbb Z^n\) and taking a union over all \(n \in \mathbb N\), it is possible to see that the set of polynomials \(\mathbb Z[x]\) with integral coefficients is <a href="https://math.stackexchange.com/questions/341349/prove-that-the-set-of-integer-coefficients-polynomials-is-countable">countable</a>. Thus there are at most a countable number of algebraic numbers (by counting the roots as you count these polynomials). As shown in the following challenge question, \(\mathbb P(\{x\}) = 0\) for any \(x \in [0,1]\). Since \(\mathbb A \cap \Omega\) is a countable union of such singleton sets, it follows by countable additivity that \(\mathbb P(\mathbb A \cap \Omega) = 0\).</p><p><strong>Challenge question 4 (related to example 9).</strong></p><ol><li>Show, using only the properties of a probability measure, that for any \(x \in [0,1]\), \(\mathbb P(\{x\}) = 0\).<li>Thus show that \(\mathbb P([a,b]) = b - a\) for <em>closed intervals</em> \([a,b] \subseteq [0,1]\) with \(a \neq 0\) and \(b \neq 1\) (although it is true for those too).<li>It is known that \(B = \sin^2(\mathbb N) = \{\sin^2(n) : n \in \mathbb N\}\) (where \(0 \in \mathbb N\)) is dense in \([0,1]\) (meaning that you can find points in \(B\) within <em>any</em> (possibly arbitrary small) open subinterval of \([0,1]\)); find the probability that you do <em>not</em> randomly choose a number in \(B\), i.e. \(\mathbb P(\Omega \setminus B)\).</ol><p>Post your solutions in the unofficial <a href="https://discord.gg/hx63ZwSXBg">Maths @ Monash Discord</a>!</p><p>We’ve now had quite a bit of experience with probability spaces, and maybe you can start to appreciate the role of measure theory in probability! Now we are finally ready, and will attempt to answer the age-old question: what is a random variable? Check out the <a href="https://subjunctivequaver.github.io/posts/measure-theory-in-probability-2/">next post</a> for the answers!</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/epic-maths-time/'>Epic Maths Time</a>, <a href='/categories/new-perspectives/'>New Perspectives</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/probability/" class="post-tag no-text-decoration" >probability</a> <a href="/tags/measure-theory/" class="post-tag no-text-decoration" >measure-theory</a> <a href="/tags/statistics/" class="post-tag no-text-decoration" >statistics</a> <a href="/tags/topology/" class="post-tag no-text-decoration" >topology</a> <a href="/tags/uni-maths/" class="post-tag no-text-decoration" >uni-maths</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Why probability and statistics need measure theory, part 1 - Epic Maths Time&url=https://subjunctivequaver.github.io//posts/measure-theory-in-probability/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Why probability and statistics need measure theory, part 1 - Epic Maths Time&u=https://subjunctivequaver.github.io//posts/measure-theory-in-probability/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Why probability and statistics need measure theory, part 1 - Epic Maths Time&url=https://subjunctivequaver.github.io//posts/measure-theory-in-probability/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/honours-thesis/">My honours thesis — minimum bases for permutation groups</a><li><a href="/posts/generatingfunctionological-proof-geometric-arithmetic-sequences/">A generatingfunctionological proof of the geometric and arithmetic sequence formulas</a><li><a href="/posts/generatingfunctionological-proof-binomial-theorem/">A generatingfunctionological proof of the binomial theorem</a><li><a href="/posts/integrating-rational-functions/">Integrating rational functions, partial fractions, and a taste of algebra, part 1</a><li><a href="/posts/measure-theory-in-probability/">Why probability and statistics need measure theory, part 1</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/uni-maths/">uni-maths</a> <a class="post-tag" href="/tags/algebra/">algebra</a> <a class="post-tag" href="/tags/calculus/">calculus</a> <a class="post-tag" href="/tags/combinatorics/">combinatorics</a> <a class="post-tag" href="/tags/measure-theory/">measure-theory</a> <a class="post-tag" href="/tags/polynomials/">polynomials</a> <a class="post-tag" href="/tags/probability/">probability</a> <a class="post-tag" href="/tags/rings/">rings</a> <a class="post-tag" href="/tags/statistics/">statistics</a> <a class="post-tag" href="/tags/topology/">topology</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/measure-theory-in-probability-2/"><div class="card-body"> <span class="timeago small" >Jun 18, 2021<i class="unloaded">2021-06-18T13:14:00+10:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Why probability and statistics need measure theory, part 2</h3><div class="text-muted small"><p> If you haven’t already read part 1, make sure you read it here first! Or else, much of the below will not make sense! Random variables: neither random, nor a variable What is a random variable? ...</p></div></div></a></div><div class="card"> <a href="/posts/generatingfunctionological-proof-geometric-arithmetic-sequences/"><div class="card-body"> <span class="timeago small" >Apr 16, 2022<i class="unloaded">2022-04-16T11:28:00+10:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>A generatingfunctionological proof of the geometric and arithmetic sequence formulas</h3><div class="text-muted small"><p> Recall from high school that a geometric sequence is a sequence \((a_n)_{n \geq 0}\) that satisfies the recurrence relation \(a_{n + 1} = r a_n\) for some fixed \(r \in \mathbb{R}\), and an arithme...</p></div></div></a></div><div class="card"> <a href="/posts/generatingfunctionological-proof-binomial-theorem/"><div class="card-body"> <span class="timeago small" >Apr 16, 2022<i class="unloaded">2022-04-16T13:00:00+10:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>A generatingfunctionological proof of the binomial theorem</h3><div class="text-muted small"><p> Make sure you have read the last post on generating functions first, else proceed at your own risk! Recall that for \(k,n \in \mathbb{N}\), the binomial coefficient is defined by \[\binom{k}{n} =...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <span class="btn btn-outline-primary disabled" prompt="Older"><p>-</p></span> <a href="/posts/measure-theory-in-probability-2/" class="btn btn-outline-primary" prompt="Newer"><p>Why probability and statistics need measure theory, part 2</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/SubjunctiveQuav">Lawrence Chen</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/uni-maths/">uni maths</a> <a class="post-tag" href="/tags/algebra/">algebra</a> <a class="post-tag" href="/tags/calculus/">calculus</a> <a class="post-tag" href="/tags/combinatorics/">combinatorics</a> <a class="post-tag" href="/tags/measure-theory/">measure theory</a> <a class="post-tag" href="/tags/polynomials/">polynomials</a> <a class="post-tag" href="/tags/probability/">probability</a> <a class="post-tag" href="/tags/rings/">rings</a> <a class="post-tag" href="/tags/statistics/">statistics</a> <a class="post-tag" href="/tags/topology/">topology</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
