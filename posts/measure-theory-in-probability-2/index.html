<!doctype html><html lang="en-AU" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Why probability and statistics need measure theory, part 2" /><meta property="og:locale" content="en_AU" /><meta name="description" content="If you haven‚Äôt already read part 1, make sure you read it here first! Or else, much of the below will not make sense!" /><meta property="og:description" content="If you haven‚Äôt already read part 1, make sure you read it here first! Or else, much of the below will not make sense!" /><link rel="canonical" href="https://subjunctivequaver.github.io//posts/measure-theory-in-probability-2/" /><meta property="og:url" content="https://subjunctivequaver.github.io//posts/measure-theory-in-probability-2/" /><meta property="og:site_name" content="Forms &amp; Formation" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-06-18T13:14:00+10:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Why probability and statistics need measure theory, part 2" /><meta name="twitter:site" content="@SubjunctiveQuav" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2026-01-03T04:11:33+11:00","datePublished":"2021-06-18T13:14:00+10:00","description":"If you haven‚Äôt already read part 1, make sure you read it here first! Or else, much of the below will not make sense!","headline":"Why probability and statistics need measure theory, part 2","mainEntityOfPage":{"@type":"WebPage","@id":"https://subjunctivequaver.github.io//posts/measure-theory-in-probability-2/"},"url":"https://subjunctivequaver.github.io//posts/measure-theory-in-probability-2/"}</script><title>Why probability and statistics need measure theory, part 2 | Forms & Formation</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Forms & Formation"><meta name="application-name" content="Forms & Formation"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.2/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return 'mode'; } static get MODE_ATTR() { return 'data-mode'; } static get DARK_MODE() { return 'dark'; } static get LIGHT_MODE() { return 'light'; } static get ID() { return 'mode-toggle'; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener('change', () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia('(prefers-color-scheme: dark)'); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { document.documentElement.removeAttribute(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage( { direction: ModeToggle.ID, message: this.modeStatus }, '*' ); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.notify(); } /* flipMode() */ } /* ModeToggle */ const modeToggle = new ModeToggle(); </script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"> <img src="/assets/img/SubjunctiveQuaver_Square_1024.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"> </a><h1 class="site-title"> <a href="/">Forms & Formation</a></h1><p class="site-subtitle fst-italic mb-0">Lawrence‚Äôs blog:<br>Formed by structure, transformed by grace</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/SubjunctiveQuaver" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github-alt"></i> </a> <a href="https://www.youtube.com/@lawrencechen11" aria-label="youtube" target="_blank" rel="noopener noreferrer" > <i class="fab fa-youtube"></i> </a> <a href="https://www.reddit.com/user/SubjunctiveQuaver/" aria-label="reddit" target="_blank" rel="noopener noreferrer" > <i class="fab fa-reddit"></i> </a> <a href="https://instagram.com/lawrencechen11" aria-label="instagram" target="_blank" rel="noopener noreferrer" > <i class="fab fa-instagram"></i> </a> <a href="https://facebook.com/lawrencechen11" aria-label="facebook" target="_blank" rel="noopener noreferrer" > <i class="fab fa-facebook"></i> </a> <a href="https://www.linkedin.com/in/lawrencechen11/" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="https://www.sporcle.com/user/LeviosaErised/quizzes/" aria-label="sporcle" target="_blank" rel="noopener noreferrer" > <i class="fas fa-map-pin"></i> </a> <a href="javascript:location.href = 'mailto:' + ['lawrence.d.chen','outlook.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Why probability and statistics need measure theory, part 2</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link"> <i class="fas fa-search fa-fw"></i> </button> <search class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1"><header><h1 data-toc-skip>Why probability and statistics need measure theory, part 2</h1><div class="post-meta text-muted"> <span> Posted <time data-ts="1623986040" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Jun 18, 2021 </time> </span> <span> Updated <time data-ts="1767373893" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Jan 3, 2026 </time> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://www.instagram.com/lawrencechen11">Lawrence Chen</a> </em> </span> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="3075 words" > <em>17 min</em> read</span></div></div></header><div class="content"><p>If you haven‚Äôt already read part 1, make sure you read it <a href="https://subjunctivequaver.github.io/posts/measure-theory-in-probability/">here</a> first! Or else, much of the below will not make sense!</p><h2 id="random-variables-neither-random-nor-a-variable"><span class="me-2">Random variables: neither random, nor a variable</span><a href="#random-variables-neither-random-nor-a-variable" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="what-is-a-random-variable"><span class="me-2">What is a random variable?</span><a href="#what-is-a-random-variable" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Let \((\Omega,\mathcal F,\mathbb P)\) be a probability space.</p><p><strong>Definition 10.</strong> A <strong>random variable</strong> is a <em>measurable</em> function \(X : \Omega \to E\), where \((E,\mathcal E)\) is the <strong>state space</strong>. We usually take \(E\) to be a topological space \((E,\mathcal T)\) (e.g. \(\mathbb R,\mathbb R^n,\mathbb C\) with the usual topologies), so that \((E,\mathcal B)\) is endowed with the <em>Borel sigma algebra</em>.</p><p>Clearly we must define measurable functions.</p><p><strong>Definition 11.</strong> A function \(f : (\Omega,\mathcal F) \to (E,\mathcal E)\) between measurable spaces is <strong>measurable</strong> if, for any measurable subset \(A \in \mathcal E\) of \(E\), its <em>preimage</em></p>\[f^{-1}(A) := \{x \in \Omega : f(x) \in A\}\]<p>is measurable in \(\Omega\), i.e. \(f^{-1}(A) \in \mathcal F\). If \((E,\mathcal T)\) is a topological space and \(\mathcal E = \mathcal B(\mathcal T)\), then \(f\) is <strong>Borel measurable</strong>.</p><p>For now, we will take \(\Omega = E = \mathbb R\), and the Borel sigma algebra on \(\mathbb R\). What are some examples of measurable functions? Well, it turns out that every function you can think of (well, with probability 1) will be measurable! One particularly nice class of measurable functions in this case are the <em>continuous functions</em>:</p><p><strong>Definition 12.</strong> A function \(f : (\Omega,\tau) \to (E,\mathcal T)\) between <em>topological spaces</em> is <strong>continuous</strong> if, for any open subset \(A \in \mathcal T\) of \(E\), its <em>preimage</em> \(f^{-1}(A)\) is open in \(\Omega\), i.e. \(f^{-1}(A) \in \tau\).</p><p>Hopefully you can see the similarity: just replace ‚Äúmeasurable‚Äù with ‚Äúopen‚Äù! Again, this may be different to the usual notion of continuity that you know (nearby inputs map to nearby outputs), but they turn out to be <a href="https://math.stackexchange.com/questions/2762135/equivalence-of-continuity-between-metric-and-topological-spaces">equivalent</a>. Here is a quick proof of the above claim:</p><p><strong>Proposition 13.</strong> Suppose \(f : (\Omega,\tau) \to (E,\mathcal T)\) is a <em>continuous</em> function. Then for a sigma algebra \(\mathcal F\) on \(\Omega\) that <em>contains</em> the Borel sigma algebra \(\mathcal B(\tau)\), the function \(f : (\Omega,\mathcal F) \to (E,\mathcal B(\mathcal T))\) is <em>measurable</em>.</p><p><em>Proof.</em> Let \(A \in \mathcal B(\mathcal T)\) be a Borel set. Recall that this means that there is a countable sequence of union/intersection/complement operations such that \(A\) is constructed from a (countable) family of open sets \((A_i)_{i \in I}\). But note that the preimage of any union/intersection/complement is the union/intersection/complement of the preimages (in general, \(f^{-1}(A \cup B) = f^{-1}(A) \cup f^{-1}(B)\), \(f^{-1}(A \cap B) = f^{-1}(A) \cap f^{-1}(B)\), and \(f^{-1}(A \setminus B) = f^{-1}(A) \setminus f^{-1}(B)\)), so it follows that \(f^{-1}(A)\) is constructed from the sets \((f^{-1}(A_i))_{i \in I}\) using the exact same sequence of operations. But \(f^{-1}(A_i)\) is open for any \(i\) by continuity of \(f\) (by definition), thus measurable (since \(\mathcal F\) contains \(\mathcal B(\tau)\), which contains all open sets in \(\Omega\)). So \(f^{-1}(A)\) is constructed from the measurable sets \((f^{-1}(A_i))_{i \in I}\) using a countable sequence of union/intersection/complement operations, so \(f^{-1}(A) \in \mathcal F\) (sigma algebras are closed under these operations). \(\square\)</p><p>This immediately gives many, many measurable functions! Assuming the sample space is \(\mathbb R\), polynomial functions, rational functions, exponentials, trigonometric functions, logarithmic functions etc. are all measurable, and so are their sums, products, quotients (where defined), and compositions (which are all continuous)! So are the minimum/maximum of two continuous/measurable functions (in fact, supremums and infimums also work). So is the wild <a href="https://en.wikipedia.org/wiki/Weierstrass_function">Weierstrass function</a>, which is differentiable nowhere, but continuous everywhere, thus measurable!</p><p><a href="https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/WeierstrassFunction.svg/2880px-WeierstrassFunction.svg.png" class="popup img-link shimmer"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/60/WeierstrassFunction.svg/2880px-WeierstrassFunction.svg.png" alt="The Weierstrass function, which is measurable." loading="lazy"></a></p><p>But it turns out that many discontinuous functions are also measurable. Let‚Äôs look at one example: the <em>signum</em> function</p>\[\operatorname{sgn} : \mathbb R \to \mathbb R, \quad x \mapsto \begin{cases} 1, &amp; x &gt; 0 \\ 0, &amp; x = 0 \\ -1, &amp; x &lt; 0 \end{cases}\]<p>(a friend-favourite, for some reason‚Ä¶). To show this, we need to show that for any Borel set \(A \subseteq \mathbb R\), its preimage \(\operatorname{sgn}^{-1}(A) = \{x \in \mathbb R : \operatorname{sgn}(x) \in A\}\) is again a Borel set in \(\mathbb R\). One approach considers 8 cases; we do only one. Suppose that \(0,1 \in A\) but \(-1 \not\in A\). Then</p>\[\operatorname{sgn}^{-1}(A) = \{x \in \mathbb R : \operatorname{sgn}(x) \in A\} = \{x \in \mathbb R : \operatorname{sgn}(x) \in \{0,1\}\}\]<p>since \(\operatorname{sgn}\) only takes on values in \(\{0,\pm 1\}\). Therefore, \(\operatorname{sgn}^{-1}(A) = [0,\infty)\); this is a Borel set since its complement is the open set \((-\infty,0)\) (and open sets are always Borel sets).</p><p><strong>Challenge question 5.</strong> Complete the above proof that the signum function is measurable by identifying the remaining 7 cases, and checking that \(\operatorname{sgn}^{-1}(A)\) is a Borel set in each case.</p><p>Going back to our example 9 with the uniform distribution on \([0,1]\), it now follows that the inclusion map \(X : \Omega \hookrightarrow \mathbb R, x \mapsto x\), is a <em>random variable</em>, since it is continuous (thus measurable). This is how we typically think of a random variable with a uniform distribution!</p><p>Briefly, let‚Äôs consider random variables from finite probability spaces. Since the natural sigma algebra is the power set (the <em>discrete topology</em>), it follows that <em>every</em> function is measurable. So <em>any</em> function \(X : \Omega \to E\) is a valid random variable. Let‚Äôs now look at random variables in a bit more depth.</p><h3 id="fun-with-random-variables"><span class="me-2">Fun with random variables</span><a href="#fun-with-random-variables" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Let‚Äôs first introduce some notation. Recall that a random variable \(X : \Omega \to E\) is a <em>measurable function</em> from a probability space \((\Omega,\mathcal F,\mathbb P)\) to a measurable space \((E,\mathcal E)\). It‚Äôs not a <em>variable</em>! And it‚Äôs not even random‚Ä¶ the ‚Äúrandomness‚Äù comes from the fact that a probability measure assigns ‚Äúchances‚Äù to different events. Let‚Äôs now combine the notion of <em>random variable</em>, with the notion of <em>probability space</em>. This is how you‚Äôve learnt random variables in high school/early university!</p><p>For the following, we take \(E = \mathbb R\). Let \(A \subseteq \mathbb R\) be a Borel set. Then since \(X\) is measurable, \(X^{-1}(A)\) is a valid event. Thus we may take its probability, and we write it in the following ways:</p>\[\mathbb P(X^{-1}(A)) = \mathbb P(\{\omega \in \Omega : X(\omega) \in A\}) = \mathbb P(X \in A).\]<p>Of these, the last is probably the most familiar. But they all mean the same thing! In fact, what we <em>mean</em> when we write \(X \in A\), is precisely the event \(X^{-1}(A)\)!</p><p><strong>Example 8 (continued from part 1).</strong> Recall this example, in which we had an infinite sequence of coin tosses and a sample space \(\Omega = \{0,1\}^\infty\). For \(n \geq 1\), consider the following random variable \(X_n : \Omega \to \mathbb R,\)</p>\[\omega = (\omega_1,\omega_2,...) \mapsto \omega_n,\]<p>which is simply projection onto the \(n\)th coordinate. For example, if \(n = 2\) and we consider the outcome \(\omega = (1,0,1,0,...)\), we get \(X_2(\omega) = 0\). We can see that this essentially measures the outcome of the \(n\)th toss: if it was a tail, then \(X_n(\omega) = 0\); if a head, then \(X_n(\omega) = 1\). Assuming that each toss independently has probability \(p \in (0,1)\) of appearing as a head, we observe the following: for any \(n\),</p>\[\mathbb P(X_n = 1) = \mathbb P(X_n^{-1}(\{1\})) = \mathbb P(\{\omega \in \Omega : X_n(\omega) = 1\}) = p,\]<p>by our assertion. Similarly, \(\mathbb P(X_n = 0) = \mathbb P(\{\omega \in \Omega : X_n(\omega) = 0\}) = 1 - p\), since</p>\[X_n^{-1}(0) \cup X_n^{-1}(1) = X_n^{-1}(\{0,1\}) = \Omega\]<p>and</p>\[X_n^{-1}(0) \cap X_n^{-1}(1) = X_n^{-1}(\{0\} \cap \{1\}) = X_n^{-1}(\varnothing) = \varnothing,\]<p>i.e. the two events \(\{X_n = 0\}\) and \(\{X_n = 1\}\) are disjoint (as expected), and their union is the sample space (this is called a <strong>partition</strong>), so the sum of the above two probabilities should be 1. (Note that here we use general properties of preimages of functions (\(f^{-1}(A \cup B) = f^{-1}(A) \cup f^{-1}(B)\), \(f^{-1}(A \cap B) = f^{-1}(A) \cap f^{-1}(B)\), and \(f^{-1}(A \setminus B) = f^{-1}(A) \setminus f^{-1}(B)\)), and when taking the preimage of a point, we often drop the curly brackets. It does <em>not</em> mean the inverse function; \(X_n\) is certainly not invertible!)</p><p><strong>Example 9 (continued from part 1).</strong> Let‚Äôs again consider the uniform distribution on \([0,1]\), and the random variable \(X : \Omega \hookrightarrow \mathbb R, x \mapsto x\) defined above. Then, for example, for \((a,b) \subseteq (0,1)\),</p>\[\mathbb P(a &lt; X &lt; b) = \mathbb P(X^{-1}((a,b))) = \mathbb P((a,b)) = b - a.\]<p>Now, recall that the composition of measurable functions is measurable, so if \(f\) is for instance continuous, then \(f(X) = f \circ X\) is also a random variable! Let‚Äôs take \(f\) to be the squaring function \(x \mapsto x^2\). Let‚Äôs investigate the random variable \(f(X) = X^2 : [0,1] \to \mathbb R\) where \(X^2(\omega) = \omega^2\):</p><p><strong>Challenge question 5 (related to example 9).</strong></p><ol><li>Find \((X^2)^{-1}(I) \subseteq [0,1]\) for any open interval \(I = (a,b) \subseteq [0,1]\). Is this a valid event (a Borel set in \([0,1]\))?<li>Thus compute the probability \(\mathbb P(a &lt; X^2 &lt; b)\).<li>For \(x \in (0,1)\), find \((X^2)^{-1}((-\infty,x])\) and thus find \(G(x) = \mathbb P(X^2 \leq x)\). What is \(G(b) - G(a)\)?<li>Can you find a function \(g : (0,1) \to \mathbb R\) such that \(\mathbb P(a &lt; X^2 &lt; b) = \int_a^b g(x)\,dx\)? (<em>Hint:</em> consider the function \(G : (0,1) \to [0,1]\), and apply the <em>fundamental theorem of calculus</em>, which implies \(\int_a^b G'(x)\,dx = G(b) - G(a)\).) This is (almost) the <em>probability density function</em> (or <em>pdf</em>) of \(X^2\).</ol><p>Post your solutions in the unofficial <a href="https://discord.gg/hx63ZwSXBg">Maths @ Monash Discord</a>!</p><h2 id="distributions-a-change-in-perspective"><span class="me-2">Distributions: a change in perspective</span><a href="#distributions-a-change-in-perspective" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="probability-distributions-and-pushforwards"><span class="me-2">Probability distributions and pushforwards</span><a href="#probability-distributions-and-pushforwards" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>A subtle but important change of perspective is to notice that for a probability measure \(\mathbb P\) on the sample space, and a random variable \(X : \Omega \to E\), we can actually define a <em>new</em> probability measure on the state space \(E\), that arises naturally from \(X\)! This is the <em>pushforward measure</em> \(\mathbb P_X = X_*\mathbb P = \mathbb P \circ X^{-1} : \mathcal E \to [0,1]\), defined by</p>\[\mathbb P_X(A) := \mathbb P(X^{-1}(A)) = \mathbb P(X \in A).\]<p>Here, \(A \in \mathcal E\) is a (Borel) measurable set. Then the triple \((E,\mathcal E,\mathbb P_X)\) is a <em>probability space</em>, induced by the random variable \(X\), so we can directly talk about probabilities using only the state space! And this is crucial in defining <em>probability distributions</em>, as we can then largely ignore the sample space!</p><p>This is something that we like to do a lot in maths: which is to start off with a structure on a set, and use a mapping to <em>transfer</em> that structure over to a different set. This is one such example; other examples of similar structure-preserving maps are continuous maps (preserving open sets), homeomorphisms (preserving topologies), isometries (preserving distances), linear transformations (preserving vector space structure), homomorphisms/isomorphisms (preserving algebraic structure), and pullbacks of bilinear forms under a linear map.</p><p>Now, let‚Äôs consider \((-\infty,x]\) which is clearly a Borel set. We define the cumulative distribution function using the probability that \(X\) takes on a value in this set:</p><p><strong>Definition 14.</strong> For a random variable \(X : \Omega \to \mathbb R\), its <strong>(cumulative) distribution function (cdf)</strong> is the measurable function \(F_X : \mathbb R \to [0,1]\), defined by</p>\[F_X(x) = \mathbb P(X \leq x) = \mathbb P(X^{-1}((-\infty,x])) = \mathbb P_X((-\infty,x]).\]<p>That is, the cdf of \(X\) gives us the probability measure of the event \((-\infty,x]\), where we push the probability measure from the sample space over to the state space! Similarly, if we have a probability space \((\Omega,\mathcal F,\mathbb P)\) with sample space \(\Omega \subseteq \mathbb R\), we can define the <strong>distribution function</strong> of the probability measure \(\mathbb P\) as \(F : \mathbb R \to [0,1]Ôºå x \mapsto \mathbb P((-\infty,x])\).</p><p>As a quick note, the cdf of a random variable \(X\) fully determines its properties, as we may recover the event \(X^{-1}(A) = \{X \in A\}\) (thus \(\mathbb P(X \in A)\)) for any Borel set \(A\) from countable unions/intersections/complements of events \(X^{-1}((-\infty,x]) = \{X \leq x\}\) with \(x \in \mathbb R\).</p><p>It is possible to see that any cdf must be <em>increasing</em> (i.e. if \(a &lt; b\), then \(F(a) \leq F(b)\)):</p><p><em>Proof</em> For \(a &lt; b\), we have</p>\[F(b) = \mathbb P((-\infty,b]) = \mathbb P((-\infty,a] \cup (a,b]) = \mathbb P((-\infty,a]) + \underbrace{\mathbb P((a,b])}_{\geq 0} \geq F(a). \square\]<p>Additionally, cdfs have <a href="https://math.stackexchange.com/questions/147612/discontinuity-points-of-a-distribution-function"><em>countably many discontinuities</em></a>, and must be <em>right-continuous</em>, meaning that not <em>every</em> increasing measurable function with codomain \([0,1]\) is the cdf of some random variable.</p><p>This change of perspective is useful, as it allows us to define when two random variables have the <em>same probability distribution</em>, even when they aren‚Äôt defined on the <em>same probability space</em>! We say that two random variables \(X : (\Omega_1,\mathcal F_1,\mathbb P_1) \to (\mathbb R,\mathcal B)\) and \(Y : (\Omega_2,\mathcal F_2,\mathbb P_2) \to (\mathbb R,\mathcal B)\) are <strong>equal in distribution</strong> if their cdfs are equal as functions: \(F_X = F_Y\); this means that \(\mathbb P_1(X \leq x) = \mathbb P_2(Y \leq x)\) for all \(x \in \mathbb R\) (note the different probability measures), or equivalently,</p>\[\mathbb P_X((-\infty,x]) = \mathbb P_Y((-\infty,x]),\]<p>which turns out to imply that \(\mathbb P_X = \mathbb P_Y\) (the <em>pushforward measures</em>) as probability measures on the state space \((\mathbb R,\mathcal B)\) (again via the <a href="https://handwiki.org/wiki/Hahn%E2%80%93Kolmogorov_theorem">Hahn-Kolmogorov theorem</a>). And hopefully this explains why the pushforward measure is so important: \(X\) and \(Y\) have the same probability distribution if and only if they induce identical probability spaces on the event space (via the pushforward measure), even if they are defined on totally different sample spaces.</p><p>Furthermore, this change in perspective allows us to ‚Äúdiscard‚Äù the sample space, and instead consider a probability measure on the state space \(\mathbb R\), in the sense that if \((\Omega,\mathcal F,\mathbb P)\) is a probability space and \(X : \Omega \to \mathbb R\) is a random variable with pushforward measure \(\mathbb P_X\), we ignore this and work only with the probability space \((\mathbb R,\mathcal B,\mathbb P_X)\), and we consider the properties of this probability space (expectation, density, etc.). This is the usual approach to learning random variables in early studies ‚Äì do you ever remember thinking about the sample space when working with random variables? Most likely not.</p><h3 id="examples-of-distributions"><span class="me-2">Examples of distributions</span><a href="#examples-of-distributions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><strong>Example 15.</strong> Lets see an example of this, coming from our previous examples. Consider the first probability space to be the example with rolling two fair dice (independently) with \(\Omega_1 = \{1,...,6\} \times \{1,...,6\}\), and the second probability space be the uniform distribution on \(\Omega_2 = [0,1]\). Clearly these random variables are vastly different. Define the random variable \(X : \Omega_1 \to \mathbb R\) as giving \(1\) if the first die resulted in an equal or higher roll than the second, or \(0\) otherwise:</p>\[X(\omega) = X((\omega_1,\omega_2)) = \begin{cases} 1, &amp; \omega_1 \geq \omega_2 \\ 0, &amp; \omega_1 &lt; \omega_2 \end{cases}\]<p>Let \(Y : \Omega_2 \to \mathbb R\) be given by the following transformation:</p>\[Y(\omega) = \begin{cases} 1, &amp; \omega \leq 21/36 \\ 0, &amp; \omega &gt; 21/36 \end{cases}\]<p>Let‚Äôs compute the cdfs of \(X\) and \(Y\). For \(X\), for any \(x \in (-\infty,0)\), we have \(X^{-1}((-\infty,x]) = \varnothing\), so \(F_X(x) = \mathbb P_X((-\infty,x]) = \mathbb P_1(\varnothing) = 0\). For \(x \in [0,1)\), \(X^{-1}((-\infty,x]) = X^{-1}(0) = \{(\omega_1,\omega_2) \in \Omega_1 : \omega_1 \geq \omega_2\}\), so</p>\[F_X(x) = \mathbb P_X((-\infty,x]) = \mathbb P_1(\{(\omega_1,\omega_2) \in \Omega_1 : \omega_1 \geq \omega_2\}) = \frac{21}{36}\]<p>by a simple combinatorial argument, and the fact that the 21 outcomes in that event are equiprobable. Now for \(x \in [1,\infty)\), \(X^{-1}((-\infty,x]) = X^{-1}(\{0,1\}) = \Omega_1\), so \(F_X(x) = \mathbb P_X((-\infty,x]) = \mathbb P_1(\Omega_1) = 1\). In summary:</p>\[F_X(x) = \begin{cases} 0, &amp; x &lt; 0 \\ 21/36, &amp; 0 \leq x &lt; 1 \\ 1, &amp; x \geq 1 \end{cases}\]<p><strong>Challenge question 6 (related to example 15).</strong> Compute the cdf of \(Y\), and show that \(X\) and \(Y\) are equal in distribution. (This then implies \(\mathbb P_X = \mathbb P_Y\) and \(\mathbb P_1(X \in A) = \mathbb P_2(Y \in A)\) for any Borel set \(A\), and we may as well forget about the original sample spaces and consider the abstract properties of their common induced probability space on \(\mathbb R\)!) If you need a reminder of how \((\Omega_2,\mathcal F_2,\mathbb P_2)\) works, the example is Example 9 in <a href="https://subjunctivequaver.github.io/posts/measure-theory-in-probability/">here</a>.</p><p>At this point, we are finally ready to <em>define</em> discrete and continuous random variables, or more fundamentally, probability distributions.</p><p><strong>Definition 16.</strong></p><ol><li>A <strong>continuous random variable</strong> \(X : \Omega \to \mathbb R\) is such that \(\mathbb P(X = x) = \mathbb P_X(\{x\}) = 0\) for all \(x \in \mathbb R\).<li>An <strong>absolutely continuous random variable</strong> \(X : \Omega \to \mathbb R\) is such that there exists a function \(f : \mathbb R \to [0,\infty]\) such that \(\mathbb P(X \in A) = \int_A f(x)\,dx\) for <em>any</em> Borel set \(A \subseteq \mathbb R\). This function \(f\) is the <strong>probability density function (density/pdf)</strong> of \(X\). (Absolutely continuous random variables are continuous.)<li>A <strong>discrete random variable</strong> \(X : \Omega \to \mathbb R\) is such that there exists a <em>countable</em> Borel set \(A\) with \(\mathbb P(X \in A) = \mathbb P_X(A) = 1\). (If \(\Omega\) is discrete, any random variable will be discrete.)</ol><p>Note how densities are defined. We start with a probability space, with a probability measure \(\mathbb P\) defined on it, and a random variable \(X\) mapping the sample space into the reals. A density is then a function that satisfies the particular property that</p>\[\mathbb P(X \in A) = \mathbb P_X(A) = \int_A f(x)\,dx\]<p>for <em>any</em> Borel set \(A \subseteq \mathbb R\), which may feel backwards. Don‚Äôt we usually start with the density function? We can, and again this approach uses the idea that we can forget about the original sample space, and study the probability space via the pushforward measure. So when we gave the normal density</p>\[f_\theta : \mathbb{R} \to \mathbb{R}, \quad x \mapsto \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)\]<p>at the start of part 1, we can either think of a probability space and a random variable which happens to have this as a density, or we can think of this density as characterising the pushforward measure of <em>some</em> random variable whose sample space is unimportant. And it is this second perspective that we tend to prefer, as the analysis (probability calculations, expectation/moments, statistics, etc.) then directly applies to <em>any</em> scenario in which the pushforward measure has the same density, even if the underlying experiment is different (as we saw in Example 15).</p><p>Next up, to tackle the problem of unifying the concepts of densities and expectations of different types of distributions, we will consider a new form of integral: the Lebesgue integral. We leave this to the next part of this series!</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/epic-maths-time/">Epic Maths Time</a>, <a href="/categories/new-perspectives/">New Perspectives</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/probability/" class="post-tag no-text-decoration" >probability</a> <a href="/tags/measure-theory/" class="post-tag no-text-decoration" >measure-theory</a> <a href="/tags/statistics/" class="post-tag no-text-decoration" >statistics</a> <a href="/tags/topology/" class="post-tag no-text-decoration" >topology</a> <a href="/tags/uni-maths/" class="post-tag no-text-decoration" >uni-maths</a> <a href="/tags/maths/" class="post-tag no-text-decoration" >maths</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted me-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Why%20probability%20and%20statistics%20need%20measure%20theory,%20part%202%20-%20Forms%20&%20Formation&url=https%3A%2F%2Fsubjunctivequaver.github.io%2F%2Fposts%2Fmeasure-theory-in-probability-2%2F" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter" > <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Why%20probability%20and%20statistics%20need%20measure%20theory,%20part%202%20-%20Forms%20&%20Formation&u=https%3A%2F%2Fsubjunctivequaver.github.io%2F%2Fposts%2Fmeasure-theory-in-probability-2%2F" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook" > <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Why%20probability%20and%20statistics%20need%20measure%20theory,%20part%202%20-%20Forms%20&%20Formation&url=https%3A%2F%2Fsubjunctivequaver.github.io%2F%2Fposts%2Fmeasure-theory-in-probability-2%2F" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram" > <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fsubjunctivequaver.github.io%2F%2Fposts%2Fmeasure-theory-in-probability-2%2F" data-bs-toggle="tooltip" data-bs-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin" > <i class="fa-fw fab fa-linkedin"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/anchor-verse-ai-activity/">Using AI to reflect spiritually: Bible anchor verse activity</a><li class="text-truncate lh-lg"> <a href="/posts/algebraist-field-guide/">An algebraist‚Äôs field guide to constructing ‚Ñ§, ‚Ñö, ‚Ñù, ‚ÑÇ, ‚Ñç and ùïÜ</a><li class="text-truncate lh-lg"> <a href="/posts/desmos-3d-plotter/">An 3D-on-2D interactive visualisation of immersed surfaces on Desmos</a><li class="text-truncate lh-lg"> <a href="/posts/measure-theory-in-probability/">Why probability and statistics need measure theory, part 1</a><li class="text-truncate lh-lg"> <a href="/posts/generatingfunctionological-proof-geometric-arithmetic-sequences/">A generatingfunctionological proof of the geometric and arithmetic sequence formulas</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/maths/">maths</a> <a class="post-tag btn btn-outline-primary" href="/tags/uni-maths/">uni-maths</a> <a class="post-tag btn btn-outline-primary" href="/tags/algebra/">algebra</a> <a class="post-tag btn btn-outline-primary" href="/tags/highlights/">highlights</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/essay/">essay</a> <a class="post-tag btn btn-outline-primary" href="/tags/frameworks/">frameworks</a> <a class="post-tag btn btn-outline-primary" href="/tags/combinatorics/">combinatorics</a> <a class="post-tag btn btn-outline-primary" href="/tags/geometry/">geometry</a> <a class="post-tag btn btn-outline-primary" href="/tags/measure-theory/">measure-theory</a></div></section></div><section id="toc-wrapper" class="ps-0 pe-4"><h2 class="panel-heading ps-3 pt-2 mb-2">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/measure-theory-in-probability/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1623844620" data-df="ll" > Jun 16, 2021 </time><h4 class="pt-0 my-2">Why probability and statistics need measure theory, part 1</h4><div class="text-muted"><p> Introduction to the problem You may have encountered continuous probability distributions such as the normal distribution. It‚Äôs often used to model things in the real world, and has nice statistic...</p></div></div></a></article><article class="col"> <a href="/posts/generatingfunctionological-proof-geometric-arithmetic-sequences/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1650072480" data-df="ll" > Apr 16, 2022 </time><h4 class="pt-0 my-2">A generatingfunctionological proof of the geometric and arithmetic sequence formulas</h4><div class="text-muted"><p> Recall from high school that a geometric sequence is a sequence \((a_n)_{n \geq 0}\) that satisfies the recurrence relation \(a_{n + 1} = r a_n\) for some fixed \(r \in \mathbb{R}\), and an arithme...</p></div></div></a></article><article class="col"> <a href="/posts/generatingfunctionological-proof-binomial-theorem/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1650078000" data-df="ll" > Apr 16, 2022 </time><h4 class="pt-0 my-2">A generatingfunctionological proof of the binomial theorem</h4><div class="text-muted"><p> Make sure you have read the last post on generating functions first, else proceed at your own risk! Recall that for \(k,n \in \mathbb{N}\), the binomial coefficient is defined by \[\binom{k}{n} =...</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/measure-theory-in-probability/" class="btn btn-outline-primary" aria-label="Older" ><p>Why probability and statistics need measure theory, part 1</p></a> <a href="/posts/desmos-3d-plotter/" class="btn btn-outline-primary" aria-label="Newer" ><p>An 3D-on-2D interactive visualisation of immersed surfaces on Desmos</p></a></nav><div id="disqus_thread"><p class="text-center text-muted small">Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://subjunctivequaver.github.io//posts/measure-theory-in-probability-2/'; this.page.identifier = '/posts/measure-theory-in-probability-2/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver( function (entries) { if (entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://https-subjunctivequaver-github-io.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] } ); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* Disqus hasn't been loaded */ if (typeof DISQUS === 'undefined') { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } } if (document.querySelector('.mode-toggle')) { window.addEventListener('message', reloadDisqus); } </script><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p> ¬© <time>2026</time> <a href="https://www.instagram.com/lawrencechen11">Lawrence Chen</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a></p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/maths/">maths</a> <a class="post-tag btn btn-outline-primary" href="/tags/uni-maths/">uni-maths</a> <a class="post-tag btn btn-outline-primary" href="/tags/algebra/">algebra</a> <a class="post-tag btn btn-outline-primary" href="/tags/highlights/">highlights</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/essay/">essay</a> <a class="post-tag btn btn-outline-primary" href="/tags/frameworks/">frameworks</a> <a class="post-tag btn btn-outline-primary" href="/tags/combinatorics/">combinatorics</a> <a class="post-tag btn btn-outline-primary" href="/tags/geometry/">geometry</a> <a class="post-tag btn btn-outline-primary" href="/tags/measure-theory/">measure-theory</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask"></div><script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.10/dayjs.min.js,npm/dayjs@1.11.10/locale/en.min.js,npm/dayjs@1.11.10/plugin/relativeTime.min.js,npm/dayjs@1.11.10/plugin/localizedFormat.min.js,npm/tocbot@4.21.2/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { /* start/end delimiter pairs for in-line math */ inlineMath: [ ['$', '$'], ['\\(', '\\)'] ], /* start/end delimiter pairs for display math */ displayMath: [ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script> <script defer src="/unregister.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-7VJB3058V3"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-7VJB3058V3'); }); </script> <script> /* Note: dependent library will be loaded in `js-selector.html` */ SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{snippet}</p></article>', noResultsText: '<p class="mt-5"></p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
